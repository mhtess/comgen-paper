// time ~/webppl-fork/webppl regression.wppl --require utils generic 1

var chain = last(process.argv) // load index as last command line index
// penultimate argument is the semantics
// generic = uncertain threshold
// some = fixed threshold at lowest threshold value
var targetUtterance = process.argv[process.argv.length - 2]

var responseDictionary = { "agree-key": true, "disagree-key": false };

var dataPath = "../../data/generics/endorsement/"
var priorFile = dataPath + "naturalGenerics-prior-trials-n57.csv",
 		endorsementFile = dataPath + "truth-judgments-n100.csv",
		endorsementCatchFile = dataPath + "truth-judgments_catch-trials.csv",
    cueValidityDataFile = dataPath + "cue-validity-2-freeProduction-trials-wProperty.csv"


var d_prior = dataFrame(utils.readCSV(priorFile).data, ["prevalence"]),
    d_cue = dataFrame(utils.readCSV(cueValidityDataFile).data, ["targetMention"]),
 		d_endorsement = dataFrame(utils.readCSV(endorsementFile).data),
		d_catch = dataFrame(utils.readCSV(endorsementCatchFile).data, ["pass"]);

var data = {
	prevalence: map(function(d){
		extend(d, {
			avoided_endval: avoidEnds(d.prevalence/100)
		})
	}, d_prior),
	endorsement: filter(function(di){
		var catchData = _.filter(d_catch, {workerid: di.workerid});
		return catchData[0].pass == 1;
	}, map(function(d){
			extend(d, {
				binaryResponse: responseDictionary[d.response]
			})
	}, d_endorsement)),
  cue: d_cue
};

// test that removing Ss who failed catch trial works properly
assert.ok(
	levels(data.endorsement, "workerid").length == sum(_.map(d_catch, "pass"))
)

var logisticFunction = function(y) {
   return 1 / (1 + exp(-y));
};

var properties = levels(data.endorsement, "Property");
// should be 21 properties
assert.ok(
  properties.length == 21
)

var regression = function(){

  var bs = {
    intercept: uniformDrift({a: -10, b: 10, width: 2}),
    prevalence: uniformDrift({a: -10, b: 10, width: 2}),
    cue: uniformDrift({a: -10 , b: 10, width: 2})
  }

  var linearFunction = function(xs){
     return bs.intercept +
     bs.prevalence * xs.prevalence +
     bs.cue * xs.cue;
  };

  var sigma = uniformDrift({a: 0, b: 10, width: 1});

  foreach(properties, function(p){

    var categories = levels(_.filter(data.endorsement, {Property: p}), "Category");
    var cueValidityData = _.filter(data.cue, {Property: p})

    // make sure there's data
    assert.ok(cueValidityData.length > 0)

    foreach(categories, function(k){

      var itemData = {
				endorsement: _.filter(data.endorsement, {Category: k, Property: p}),
				prevalence: _.filter(data.prevalence, {Category: k, Property: p})
			};

      // make sure there's data
      assert.ok(
        (itemData.prevalence.length > 0) && (itemData.endorsement.length > 0)
      )

      // analyze prevalence data
      var prevalenceParams = {
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 20})
      };

			var prevalenceShapes = betaShape(prevalenceParams);

      mapData({data: itemData.prevalence}, function(d){
        // display(Beta(prevalenceShapes).score(d.roundedPrevalence))
				observe(Beta(prevalenceShapes), d.roundedPrevalence)
			});

      // analyze cue validity data
      var cueValidity_theta = uniformDrift({a: 0, b: 1, width: 0.2}),
          cueValidity_k = _.filter(cueValidityData, {targetMention: 1}).length,
          cueValidity_n = cueValidityData.length;

      // display(Binomial({p: cueValidity_theta, n: cueValidity_n}).score(cueValidity_k))
      observe(Binomial({p: cueValidity_theta, n: cueValidity_n}), cueValidity_k)

      var predictors = {
        prevalence: beta(prevalenceShapes),
        cue: cueValidity_theta
      };

      query.add(["prior", "prevalence_mean", p, k], prevalenceParams.g)
      query.add(["prior", "prevalence_sampleSize", p, k], prevalenceParams.d)
      query.add(["prior", "cue", p, k], cueValidity_theta)

      var prediction = linearFunction(predictors),
          prediction_withNoise = gaussian({mu: prediction, sigma: sigma}),
          logisticPrediction = Bernoulli({p: logisticFunction(prediction_withNoise) })

      var genericsData = _.map(itemData.endorsement, "binaryResponse");

      mapData({data: genericsData}, function(d){
        // display(logisticPrediction.score(d))
        observe(logisticPrediction, d)
      })

      query.add(["predictive","generic", p, k], expectation(logisticPrediction) )

    })

  })

  query.add(["param", "beta", "intercept", "NA"], bs.intercept)
  query.add(["param", "beta", "prevalence", "NA"], bs.prevalence)
  query.add(["param", "beta", "cue", "NA"], bs.cue)
  query.add(["param", "sigma", "NA", "NA"], sigma)

  return query
}

//
var totalIterations = 50000, lag = 20;
var mhiter = totalIterations/lag, burn = totalIterations / 2;

var outfile = 'results-generics-jointModel-regressionPrevCV-'+totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'


var posterior = Infer({
  model: regression,
	method: "incrementalMH",
  samples: mhiter, burn: burn, lag: lag, verbose: T,
  verboseLag: mhiter / 20,
	stream: {
		path: "results/" + outfile,
		header: ["type", "param", "property", "category", "val"]
	}
})

"written to " + outfile;
