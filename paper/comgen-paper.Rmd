---
title             : "The Language of Generalization"
shorttitle        : "The language of generalization"

author: 
  - name          : "Michael Henry Tessler"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 316, Stanford, CA 94305"
    email         : "mhtessler@stanford.edu"
  - name          : "Noah D. Goodman"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
    
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  - \usepackage{amsmath}
  - \usepackage{graphicx}
  - \usepackage{subcaption}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  
author_note: >
  This manuscript is currently in prep. Comments or suggestions should be directed to MHT.

abstract: > 
    Language provides simple ways of communicating generalizable knowledge to each other (e.g., "Birds fly", "John hikes", "Fire makes smoke"). Though found in every language and emerging early in development, the language of generalization is philosphically puzzling and has resisted precise formalization. Here, we propose the first formal account of the language of generalization that makes quantitative predictions about human understanding. We test our model in three diverse domains: generalizations about categories (generic language), events (habitual language), and causes (causal language). The model explains the gradience in human endorsement through the interplay between a simple truth-conditional semantic theory and diverse beliefs about properties. This work opens the door to understanding precisely how abstract knowledge is learned from language. 
  
keywords          : "genericity, generalization, generics, pragmatics, semantics, Bayesian modeling"
wordcount         : "20000"

bibliography      : ["generics.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
toc               : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}

\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}
\newcommand{\ndg}[1]{{\textcolor{Green}{[ndg: #1]}}}
\newcommand{\red}[1]{{\textcolor{Red}{#1}}}

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=6, fig.height=5, fig.crop = F, fig.path='figs/',
                      echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T)

```


```{r libraries, cache = F}
library(papaja)
library(formatR)
library(rwebppl)
library(xtable)
library(tidyverse)
library(forcats)
library(langcog)
library(coda)
library(ggthemes)
library(ggrepel)
library(jsonlite)
library(gridExtra)
library(lme4)
library(knitr)
library(kableExtra)
library(cowplot)
library(magick)
library(viridis)
theme_set(theme_few())
estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
logmeanexp <- function(x){
  x.num <- as.numeric(x)
  xstar = max(x.num)
  return(xstar + log(mean(exp(x.num - xstar))))
}

compute_r2 <- function(df,v1, v2, sigfigs = 3){
  return(format(cor(df[[v1]], df[[v2]])^2, digits = sigfigs))
}

compute_mse <- function(df, v1, v2, sigfigs = 3){
  return(format(mean( (df[[v1]]-df[[v2]])^2), digits = sigfigs))
}

project.path <- "../"
options("scipen"=10) 
```

<!-- 
possible titles:
- Communicating generalizations
- The language of generalization
- The language of generalization: Probability, vagueness, and interaction
-->

<!-- Generalizations are central to human understanding and language provides simple ways to convey them (e.g., "Birds fly"). -->
<!-- The language of generalization is ubiquitous in everyday discourse and child-directed speech.  -->
<!-- The major issue in formalizing generalization in language is determining which statements are true or which are false. -->
<!-- Using an information-theoretic probabilistic model, we explore the hypothesis that the meaning of these linguistic expressions is *simple but underspecified*, and that general communicative principles can be used to establish a more precise meaning in context.  -->
<!-- To test this theory, we examine endorsements of generalizations about three different domains: categories (*generic language* e.g., "Birds fly"), events (*habitual language* e.g., "John runs"), and causes (*causal language* e.g., "Staring at the sun makes you go blind").  -->
<!-- Across these diverse domains, we find that our model explains the wide variance in human endorsements of language conveying generalization, while simpler models fall short. -->
<!-- Ours is the first formal theory that makes precise, quantitative predictions about human understanding of the language of generalization. -->
<!-- The results demonstrate that the context-sensitivity of such language emerges from the interaction of an underspecified meaning with diverse beliefs about properties.  -->

<!-- Knowledge that extends beyond the present context is crucial to thrive in our open-ended, dynamic world. Yet such knowledge can be difficult to extract from the environment. Fortunately, we are not limited to acquiring generalizations on our own; language allows us to communicate generalizations to each other (e.g., “Asparagus berries are poisonous”, “John hikes”, “Drinking milk makes your bones strong"). In this talk, I’ll argue that three ingredients are necessary to understand generalizations: Probability, vagueness, and context. I formalize these ingredients in an information-theoretic probabilistic model that makes quantitative predictions about human understanding of generalizations. Across diverse domains, I find that the model explains the gradience in multiple dependent measures, while simpler models fall short. This is the first formal theory that makes accurate and precise predictions about human understanding of generalizations in language and is the first step towards building models that can learn abstract knowledge from language. -->

# Introduction 

<!-- Learning that an object tends to have a property, an entity tends to exhibit a behavior, or a cause tends to produce an effect can be crucial to thrive in our open-ended world. -->
Knowledge that extends beyond the present context is crucial to thrive in our open-ended, dynamic world. 
Yet such knowledge can be difficult to extract from the environment: The relevant observations may be costly (e.g., learning that a plant is poisonous) or rare (e.g., understanding that lightning strikes tall objects).
Fortunately, we are not limited to acquiring generalizations on our own; language allow us to communicate generalizations to each other.
By sharing generalizable knowledge, we flourish collectively without individually needing to taste potentially-poisonous plants or personally witness lightning strikes.
Being able to flexibly communicate generalizations from one generation to the next supports the faithful transmission of knowledge necessary for culture to cumulatively evolve [@Tomasello1999; @Henrich2015].

<!-- Generalizations can be acquired from the world by drawing inductive inferences from observations [@Baldwin1993; @Xu2008; @Dewar2010]. \ndg{cite older stuff. eg hume} -->
<!-- Cooperative teachers can facilitate inductive learning by supplying helpful observations to the learner [@Csibra2009; @Tomasello1999; @Butler2012]. -->
<!-- At around a child's first birthday, however, the learner gains access to a new, human-unique source of data: language. -->
<!-- Minimally, language fosters generalizations by bringing attention to objects being of the same kind through the use of labeling [e.g., "This is a dog"; @Gelman1986; @Gopnik2000; @Graham2004; @Markman1989; @Schulz2008]. -->
<!-- Objects have many properties though; when speakers attach properties to kind-labels (e.g., "Dogs bark"), listeners hear a generalization. -->
<!-- \ndg{this par doesn't really do much} -->

<!-- Certain linguistic expressions encode generalizations. -->
<!-- Language provides multiple, distinct ways of encoding generalizations. -->
The *language of generalization* covers a diverse swath of natural language expressions.
Generic language conveys generalizations about categories [e.g., "Dogs have four legs"; @Carlson1977; @Cohen1999; @Leslie2007; @Nickel2008] and is the most well-studied case in the language of generalization.^[
  Some writers refer to the all of the *language of generalization* as "generic language" or generics.
  In both the empirical and theoretical literatures, however, analysis and experiments often focus only on generalizations about categories. 
  We use the more narrow-scoped terms (e.g., generics, habituals, and causals) to highlight the diversity of semantic types being predicated.
]
In contrast to statements about concrete individuals (e.g., "Rufus has four legs"), generic statements refer to inherently unobservable categories (e.g., the category of \textsc{dog}) and convey information that extends beyond the present context, a fact which children as young as 2 appreciate [@Cimpian2008].
Simple events (e.g., "John ran yesterday") can be generalized into habitual sentences (e.g., "John runs"), and even events of complex inferential types such as actual causal events (e.g., "This fire caused that smoke") can be described in generalization (e.g., "Fire causes smoke").

Understanding the language of generalization is a project with far-reaching implications.
The language of generalization is ubiquitous in everyday conversation, is found in every language [@Behrens2005; @Carlson1995], and conveys rich meanings, impacting motivation [@Cimpian2007], transmitting stereotyped beliefs about social categories [@Rhodes2012], and making meaning from experience [@Orvell2017].
It is highly-prevalent in child-directed speech [@Gelman2008] and its ability to refer to abstractions beyond the present context suggests its centrality to the growth of conceptual knowledge [@Gelman2004].

<!-- Generics are just one case in the language of generalization, however; events can be described in generalization (*habitual language*; e.g., "Mary swims after work.") as well as causal relationships (*causal language*; e.g., "Staring at the sun makes you go blind."). -->

<!-- Generics are ubiquitous in everyday conversation as well as in child-directed speech [@Gelman2008].  -->
<!-- Additionally, generics are the primary way by which speakers discuss social categories, and thus are key to propagating stereotypes [@Gelman2004; @Rhodes2012; @Leslie2015] and impacting motivation [@Cimpian2010]. -->
<!-- Thus, an understanding of the language of generalization that extends to a wide variety of types (e.g., categories, events, causes)  -->

<!-- Thus, an understanding of generalization as a singular phenomenon in language  -->
<!-- promises to provide an understanding of a wide variety of linguistic expressions with rich meanings. -->

<!-- Generic statements ascribing properties to categories are just one kind of generalization found in language.  -->
<!-- Individual entities can also be talked about in generalization, using so-called  -->
<!-- <!-- Recent evidence suggests talking about the other in generalization (using so-called *generic You*) can help make meaning from difficult situations   [e.g., "You never know what will happen on a blind date."; @Orvell2017]. -->
<!-- Communicating about causality can also take the form of communicating a generalization about a causal event  -->
<!-- What these statements have in common is that they convey generalizations, or exhibit *genericity* [@Carlson1977; @Carlson1995]. -->

Despite its ability to convey abstract knowledge, its ubiquity in discourse, and its relative morphosyntactic simplicity, the language of generalization displays subtle context-sensitivities that make it difficult to formalize.
"Robins lay eggs" sounds true and "Robins are female" does not. 
Yet in each case, only 50% of the category have the property (i.e., only the females lay eggs). 
"Mosquitos carry malaria" sounds true despite malaria being present in only a tiny fraction of mosquitos. 
Even more perplexing: "Supreme Court Justices have even social security numbers" is thought to be intuitively a bad sentence even if it were the case that on the current bench, nine out of nine justices have even social securtity numbers [i.e., when the sentence "All Supreme Court Justices have even social security numbers" is true; @Cohen1999].
Similar context-sensitivity can be observed with habituals: Say Mary climbed mountains 3 times last year, the habitual "Mary climbs mountain" seems well-supported. 
Yet, if John went for a run 3 times in the last year, we probably should not say that "John runs".


<!-- When we hear "Dogs bark", it sounds like a universal statement, as in "All dogs bark". -->
<!-- But the property does not apply to all dogs: Basenji dogs are barkless, for example. -->

<!-- The generic could signal something weaker like "Most dogs bark". -->

<!-- However, *most* mosquitos do not carry malaria (in fact, only a tiny fraction do), but "Mosquitos carry malaria" is intuitively true. -->
<!-- *most mosquitos* do not carry malaria, while the statement "Mosquitos carry malaria" is intuitively true. -->
<!-- The only *quantifier* that would permit such a statement would be *some* (e.g., "Some mosquitos carry malaria"). -->
<!-- But weakening the generalization to mean *some* is too permissive: Some robins are female (in fact, half of them are), but endorsing "Robins are female" seems odd. -->
<!-- Even more perplexing: Those very same female robins lay eggs, and "Robins lay eggs" is a perfectly fine thing to say. -->

These observations have led some to conclude that the literal meaning of a generic statement involves more than just the number of members of the category who have the property, otherwise known as the *prevalence* of the feature in the category.
<!-- (or the probability of a member of the category having the property e.g.,  $P(x \text{ is friendly} \mid x \text{ is a dog})$) is not sufficient to make generalizations ("Dogs are friendly") true or false. -->
Instead, generic statements are thought of semantically as a direct, linguistic manifestation of conceptual relations [@Leslie2008; @Prasada2000; @Prasada2012]. 
<!-- Conceptual accounts of generics emphasize the structure of *generic knowledge* [@Prasada2000], and view generic utterances as the way of expressing special, mental relationships between kinds and properties [@Leslie2008; @Prasada2012].  -->
<!-- Indeed, generics can be true for a range of prevalence or frequency levels [@Khelmani2012; @Prasada2013]. -->
For example, the statements "Bishops move diagonally" or "The Speaker of the House succeeds the Vice President" are true not because of a tendency on behalf of the category to uphold the property, but rather the existence of a conceptual relationship (e.g.,  what it means, in the game of chess, to be a bishop).
True generics can be supported by different underlying types of category--property relations [e.g., principled vs. statistical connections; @Prasada2006], and thus support qualitatively different inferences [e.g., "Being striped is one aspect of being a tiger" is generally endorsed, while "Carrying malaria is one aspect of being a mosquito" is not, even while "Tigers are striped" and "Mosquitos carry malaria" are both intuitively true; @Prasada2013].
This conceptual view of generics has been influential in psychology, because it predicts qualitative differences between different kinds of generics. 
<!-- Still, the theory is not sufficiently precise to make any quantitative predictions. -->

Insofar as there is a single class of linguistic expressions that convey generalization, there should be something common to them all: a literal meaning that unifies generic, habitual, and causal language.
In this paper, we propose such a semantic core based on probability and formalized using the standard tools of truth-functional semantics [@Montague1973; @Cohen1999] .
A semantics based on probability is not enough, however.
We propose that the meaning of generalizations is underspecified or *vague* and that listeners derive a more precise interpretation in context.
The fact that generics are vague, however, does not preclude them from being treated with formal models.
We draw upon the tools of Bayesian models of cognition [@Tenenbaum2011] to formalize the vagueness and context-dependence of generic language [@Frank2012; @GoodmanLassiter].
By its instantiation in a formal model, this hypothesis has meaningful conditions under which it can be tested.
It is also the first theory to make quantitative predictions about human understanding of generalization in language.
<!-- With these ideas, we create an endorsement model, that describes what makes generalizations in language true or false. -->
<!-- Our model is the first to make quantitative predictions about human endorsements of generalizations in language. -->


The paper is organized as follows. 
In Section 1, we describe the computational model of interpreting generalizations which has three components: Probability, vagueness, and context. 
<!-- formalizes the hypothesis that the core meaning of a generalization in language is a vague probability and articulates it in a model of language understanding in which relevant background knowledge is formally described. -->
Having defined a model of interpretation, we then describe an information-theoretic, communicative linking function from interpretation to judgments about the truth or acceptibility of a sentence.
The model as articulated predicts fine-grained, quantitative effects of background knowledge, which we both measure and manipulate across our three empirical case studies (Sections 2-4): generalizations about categories (*generic language*), events (*habitual language*), and causes (*causal language*). 
We compare our model to two previously articulated quantitative models of generics as well as a lesioned-version of our model.
In all cases, we find a very strong agreement of our model's predictions to human elicited endorsements, where the simpler models fall short.
We conclude our paper with a discussion of open-questions for this approach, relation to linguistic and philosophical approaches to generics, and a few sketches of worked examples of other phenomenology in generics. 

<!-- This work opens the door to understanding generalizations in richer, pragmatic language contexts and building models that learn abstract knowledge from language. -->

<!-- relevant background knowledge used to understand a generalization in context, and use these components to develop a computational model of endorsement. -->
<!-- The endorsement model's predictions depend upon relevant background knowledge and the prevalence communicated, which we demonstrate via simulation. -->
<!-- Across these three case studies, we both measure and manipulate background knowledge and the prevalence communicated, measuring their effects on endorsement of generalization sentences.  -->


<!-- To do so, we look to probability, the universal currency of belief and a useful representation for human generalization from observations [@Shepard1987; @Tenenbaum2001]. -->
<!-- Given that certain probabilities are the result of inductive generalization, it would make sense that these are the object of communication for the language of generalization. -->
<!-- \ndg{cuttoff / threshold not mentioned before this, need to introduce...} -->
<!-- However, it is not possible to develop a single cut-off for when the generalization should hold, due to examples like "Birds lay eggs" vs. "Birds are female". -->
<!-- Rather than throw-out the quantitative formalization of the threshold semantics, we posit that the threhsold is *underspecified* in the literal meaning of a generalization, and that listeners' background knowledge and the communicative context can be used to derive more precise interpretations in the moment.  -->

<!-- To formalize a model of endorsement (i.e., what makes the statements true or false), we consider the communicative function of a generalization by explicitly modeling the background knowledge a language interpreter would bring to bear when understanding generalizations. -->



<!-- It's been suggested that the mind has cognitive primitives that directly dictate what generalizations are true or false. -->
<!-- One such primitive is the ability to priviledge *characteristic features*: For an animal, their mode of reproduction is a characteristic feature.  -->
<!-- Thus, whatever their mode of reproduction may be will make a true generic statement (e.g., "Robins lay eggs"), regardless of the actual prevalence of the feature. -->
<!-- *Horrifying* or *striking* information is also priviledged and creates true generics, which is why "Mosquitos carry malaria" is true -->





<!-- Specifically, we formalize an account where the core meaning of a generalization in language is a *simple but underspecfied* function of probability and where context helps resolve the underspecification. -->
<!-- In its simplest form, context takes the shape of interlocutors' shared beliefs about the relevant properties or categories under discussion [cf., @Grice1975; @Clark1996; @Levinson2000]. -->
<!-- We then ask what a rational speaker---who can only either endorse the generalization or stay silent---would say in different contexts; this is our formal model of endorsement. -->
<!-- We show how the decision to endorse depends in systematic ways on the shared prior knowledge of the interlocutors. \mht{"interlocutors" may be confusing here...} -->
<!-- We test this theory in three distinct case studies---generalizations about categories, events, and causes---by both measuring and manipulating prior knowledge, showing that it is strongly and causally related to the endorsement of generalizations in the ways predicted by our model. -->


<!-- (cumulative $r^2(N) = 0.XX$). -->
<!-- In the final section of the paper, we discuss the generality of our approach and pave a path to unifying the extant psychological, linguistic, and philosophical literatures on generalization in language. -->
<!-- We also show how our endorsement model is a special case of a speaker model in a rational framework of communication.  -->

# Computational Framework

Generalizations are used to make predictions about events or properties of instances that an agent has yet to experience [@HumeTHN].
People readily predict that the next dog they encounter will have four legs, drinking another cup of coffee will cause jitters, and a new day will find people that we know doing what they habitually do. 
In each case, we assign a specific exemplar $x$ to a category $k$, and make a prediction that it will have feature $f$.
This prediction can be described by a conditional probability: $P(x \in f \mid x \in k)$, the probability that $x$ will have $f$ given that it is in $k$ (formally, an instance of $k$ will be in the set of things that have $f$), which we will refer to as the *prevalence* and for convenience write as $p = P(f \mid k)$.
Our *prevalence* $p$ is a *prevalence in the mind*, a latent sense that a future instance of a category would have a particular property; others might call this projectibility [@Goodman1955].
The targets of our predictions can vary widely: They may be objects (a dog), events (a coffee drink), or more fine-grained types (a person on a particular day).
The properties also vary (e.g., having fur, causing jitters, going to the gym).
Yet the mathematical description of the inductive belief is always given by a probability $P(f \mid k)$.

<!-- a useful representation  -->
<!-- How do we come to know things?  -->
<!-- How does one acquire inductive beliefs? -->
Probability is a useful representation for human generalization from observations [@Shepard1987].
If you observe several *wugs* (a novel category) that have two legs, you might infer that all wugs have two legs.
But not all properties have such strong projectibility.
Seeing a wug with broken wings tells you comparatively less about other wugs having broken wings [@Nisbett1983].
Abstract, potentially domain-specific, beliefs about the projectibility of different properties can be represented by a probability distribution over the prevalence $P(p)$ [@Kemp2007].
By assuming some generative process that could produce one's observations $o$---the likelihood $P(o \mid p)$---Bayes' Theorem provides the mathematically correct way to update one's prior beliefs from observations $o$: $P(o \mid d) \propto P(o \mid p) \cdot P(p)$  [@Tenenbaum2001].

<!-- To do so, we look to probability, the universal currency of belief and  -->
<!-- Given that certain probabilities are the result of inductive generalization, it would make sense that these are the object of communication for the language of generalization. -->

<!-- But we do not always have access to  -->
Observational data is not always available, however.
Instead, we must listen to others to learn about properties that are costly to observe (e.g., *staring at the sun makes you go blind*), events that are statistically unlikely (e.g., *lightning strikes tall objects*), or any aspect of the world that we have yet to experience.
Fortunately, language provides simple ways of communicating generalizations.


<!-- Here, $P(d \mid h)$ is the observer's generative model of the observed data.  -->
<!-- It is conditional on $h$ because the probability of various direct observations depends upon the prevalence that the observer assumes.  -->
<!-- Generalization from observational evidence is limited, however, in its capacity to describe how the mind builds complex theories of the world or how culture accumulates across generations. -->
<!-- How do we acquire these generalizations? -->
<!-- For abstract, generalizable knowledge to remain in a culture, it must be faithfully transmitted between individuals and across generations [@Tomasello1999], and language provides simple ways to communicate generalizations. -->
<!-- The human capacity to generalize from observations, deriving $h$ from example $x$s, has been studied extensively in cognitive and developmental psychology [@Nisbett1983; @Baldwin1993; @Heit2000]. -->
<!-- From a very young age, children draw strong inferences about nonobvious object properties from just a few examples [@Baldwin1993; @Gopnik2000;  @XuTenenbaum2007]. -->
<!-- Such inductive generalization can be described by the Bayesian probability calculus: An observer's initial beliefs or state of knowledge---called a prior belief distribution---is updated through experience (i.e., after making observations) and becomes a posterior belief distribution (what they belief *a posteriori*).  -->
<!-- This posterior distribution becomes the observer's prior for the next observation she makes: it thus informs her predictions about unobserved instances. -->

<!-- As a concrete example, consider a learner investigating the feature \textsc{barks} ($f$) for the category \textsc{dog} ($k$). -->
<!-- $h$ describes the learner's subjective probability that the next dog she encounters will bark^[At the moment, we assume the feature \textsc{barks} is an all-or-none Boolean property. Later, we will see how the presence of this feature itself can be thought of as a generalization over events of barking.], or more abstractly, her belief about the barking capacity of dogs. -->
<!-- That is, $h = P(x \text{ barks} \mid x \text{ is a dog})$. -->
<!-- The learner does not know $h$, but has some idea about what $h$ could be; this is represented by $P(h)$, the learner's prior beliefs about how likely it is that $x$ will bark given that $x$ is a dog. -->

<!-- The observer goes around the world, encountering dogs and taking note of how many bark. -->
<!-- This could be represented as a number of positive examples $d$ out of a number of total examples $n$.  -->
<!-- With the weak assumption that the dogs she has observed were all independent and identically-distributed (*i.i.d.*) random samples from the category of dogs, the likelihood of her observations are given by the Binomial distribution.  -->
<!-- That is, $d \sim  \text{Binomial}(n, h)$, where $d$ is the number of dogs she has seen that bark, $n$ is the total number of dogs she has seen, and $h$ is the prevalence of barking among dogs. -->
<!-- This is called a likelihood function: It determines how well a given value of $h$ predicts the observed $d$.  -->
<!-- Given a formal description of the learner's state of knowledge before any observations $P(h)$ and the learner's assumptions about how the data she observed were generated (e.g., the *i.i.d.* assumption), what a learner should believe after having seen the data is proportional to the product of these two terms, as given by Bayes' Rule: -->


<!-- $P(h \mid d)$ is then the strength of the learner's belief in the next dog she encounters barking. -->
<!-- This simple idea of integrating observational evidence with prior knowledge is surprisingly powerful in explaining a multitude of diverse phenomena, from perception to word learning to inductive reasoning [e.g., @Tenenbaum2006; @Tenenbaum2011]. -->
<!-- \ndg{what is this par doing for us? delete?} -->
<!-- Generalization from examples shows complex sensitivites to the kind of observations, and even how those observations came to be observed in the first place. -->
<!-- For instance, observing that an indigenous person living on a remote island *is brown and obese* provides considerably more information about the skin color of other islanders than about their weight [@Nisbett1983]. -->
<!-- This subtlety can be modeled by incorporating heiarchical structure into the prior belief distribution of a Bayesian model, allowing the model to represent and reason flexibly about different kinds of properties [@Kemp2008]. -->
<!-- Observations that are generated by an intentional agent can lead to similarly subtle inferences, like deconfounding otherwise ambiguous causal evidence [@Goodman2009]. -->
<!-- Yet generalizations from observational evidence is limited in its capacity to describe how the mind builds complex theories of the world or how culture accumulates across generations. -->
<!-- Relying upon observations would be particularly problematic, for example, to learn about properties that are costly to observe (e.g., *staring at the sun makes you go blind*) or events that are statistically rare (e.g., *lightning strikes tall objects*). -->
<!-- How do we acquire these generalizations? -->
<!-- For abstract, generalizable knowledge to remain in a culture, it must be faithfully transmitted between individuals and across generations [@Tomasello1999], and language provides simple ways to communicate generalizations. -->

## Communicating generalizations

The language of generalization is easy to spot when a property, that could apply to an individual, is predicated of a category (e.g., "Dogs have four legs"; *has four legs* could apply to an individual as in "This dog has four legs").
In the semantics literature on generics, bare plural sentences of this kind are sometimes described as *characterizing sentences* in contrast with *kind-denoting* sentences where the property can only meaningfully apply to the category as a whole (e.g., "Dinosaurs are extinct"; *extinct* cannot apply to an individual dinosaur).
<!-- Dinosaurs are exctinct ~ John is a smoker? -->
Generalization can also manifest when describing instances of an individual [*habitual language*; e.g., "John smokes"; @Carlson1977; @Carlson2005].
Verbs like *causes* or *makes* also seem to convey generalization, in this case, about an instance of an actual causal event (*causal language*; e.g., "Staring at the sun makes you go blind"). 
Psychologists, linguists, and philosophers have long studied the language of generalization, as it appears very simple (e.g., syntactically) yet its meaning is difficult to formalize.^[
  We further distinguish the problem of formalizing a *meaning* for the language of generalization as opposed to the problem of *identifying* generalizations. 
  Syntax alone is neither necessary nor sufficient for a listener to know that the sentence conveys a generalization  (e.g., indefinite singulars can encode generalizations: "A dog has four legs" and bare plurals may not: "Dogs are on my front lawn").
  Our analysis thus begins once a sentence has been disambiguated as conveying a generalization. 
]

If generalization from observations can be described by a probability $p$, it is natural to posit that same construct will be at the heart of a semantic theory of the language of generalization (Ingredient 1: Probability).
In semantics, belief updating generally passes through Boolean *truth values* [@Montague1973].
The simplest way to derive a Boolean from a scalar quantity like probability is via a *threshold semantics*: The utterance is true if the relevant scalar value is above a threshold.
For example, the sentence "Some dogs have four legs" is believed to be literally true if the chances that an individual dog will have four legs is more than 0%: $\denote{some}(p) = \{p > 0\}$.
"Most dogs have four legs" can also be described as a threshold on prevalence (e.g., the chances that a dog will have four legs is greater than 50%): $\denote{most}(p) = \{p > 0.5\}$.
Thus, the simplest semantics for a generalization would also be a threshold on the prevalence: $\denote{gen}(p, \theta) = \{p >\theta\}$.

The obvious next question for such a representation concerns $\theta$: What threshold is appropriate?
It has been argued that generic language is more fundamental than quantified language [e.g., "some", "most"; @Leslie2007; @Gelman2009], which can be described using particular values of $\theta$: $\denote{some}(p) = \{p > 0\}$; $\denote{most} = \{p > 0.5\}$.
In a probabilistic representation, states of uncertainty are more fundamental than states of certainty (e.g., it is a special case when an agent with probabilistic beliefs is certain about something; the more typical case is that they are uncertain). 
Thus, if quantifiers have *certain* thresholds ("some": greater than 0; "most" greater than 0.5), then perhaps generics have *uncertain* thresholds.
We formalize this underspecification of meaning (Ingredient 2: Vagueness) by putting a probability distribution over $\theta$: $P(\theta)$ [@Lassiter2013; @Lassiter2015; cf., @Qing2014].

Finally, the meanings of linguistic expressions manifest in their capacity to convey information from speaker to hearer [@Grice1975; @Clark1996; @Levinson1995].
Thus, the final ingredient to our model is *context* (Ingredient 3), which must be minimally formalized as a listener's prior knowledge about the property $P(p)$ and which we describe in more detail below.

Putting these three ingredients (probability, vagueness, and context) together, we get the following model of generic interpretation: 

\begin{eqnarray}
L(p, \theta \mid u) &\propto& {\delta_{\denote{u}(p, \theta)}  \cdot P(\theta) \cdot P(p)} \label{eq:L0}
\end{eqnarray}

We denote this probabilistic generic interpretation model by $L$ to indicate that it is modeling a listener updating their beliefs according to the truth-functional meaning of an utterance.
Formally, the truth-functional meaning is represented by the Kronecker delta function  $\delta_{\denote{u}(p, \theta)}$ that returns probabilities proportional to $1$ when the utterance is true (i.e., when $p > \theta$) and $0$ otherwise.

\begin{eqnarray}
\delta_{\denote{u_{gen}}(p, \theta)} &\propto  & \begin{cases}
1 & \text{if } p > \theta \\
0 & \text{otherwise}
\end{cases}\label{eq:delta}
\end{eqnarray}

Following @Lassiter2015, we formalize the vagueness in the meaning of generics $P(\theta)$ as a uniform distribution over the support of $P(p)$.

<!-- The extreme flexibility of generalizations (e.g., "Mosquitos carry malaria"; "Birds lay eggs" vs. "Birds are female") suggests that no fixed threshold would suffice.  -->
<!-- Rather than throw out the threshold-semantics, we posit that the threshold is *underspecified* in the literal meaning and is contextually-determined in a way analogous to how gradable adjectives like *tall* have contextually-determined thresholds [e.g., what counts as tall for a four-year-old is different than what counts as tall for an adult; @Kennedy2007; @Lassiter2013]. -->

<!-- So what threshold $\theta$? should be used for the generalizations?  -->
<!-- Unlike quantified language which have fixed-thresholds, we posit that the language of generalizations is *underspecfied* with respect to the actual truth-functional threshold $\theta$. -->




### Endorsement model

In this paper, we are interested in explaining truth judgments (e.g., "Robins lay eggs" is intuitively true; "Robins are female" is not).
If the interpreter is a kind of simple listener model, then we can ask whether an agent would bother to produce the generalization to this listener.
The endorsement model then acts as a kind of speaker, reasoning about how the interpreter model (the listener) would understand the utterance.
This kind of model formalizes the basic aspects of communicative reasoning and is the simplest instantiation of a Rational Speech Act model [@Frank2012; @Goodman2016].

We interpret the endorsement task (e.g., *true* vs. *false*; *agree* vs. *disagree*) as supplying two alternatives to the endorsement model: produce the generalization vs. a null alternative [@Franke2014cogsci; @Degen2014].
For simplicity, we take the null alternative to be an informationless "silent" utterance which is always true: 
$\denote{null}(x, \theta) = \text{True}$.^[
  The null alternative can be realized in at least two other ways: the negation of the generalization (e.g., "It is not the case that Robins lay eggs") or the negative generalization (i.e., "Robins do not lay eggs").
  All results reported are similar for these two alternatives, and we use the alternative of the "silent" utterance for simplicity.
]

The utterance encoding a generalization updates the interpreter model's beliefs about the prevalence of a feature in the category being referred to, which we call the *referent prevalence*. 
The endorsement model has a particular referent prevalence in mind and decides if the generalization or the null alternative is better at conveying that to the interpreter. ^[
  A more general version of this model can relax the assumption that the endorsement model has access to a specific prevalence $p$ that it wants to communicate.
  Rather, the endorser may have a distribution over $p$ for the category $k$, corresponding to the endorser's uncertain beliefs about the prevalence of the property for the referent category. 
  In this situation, we would define the endorsement model decision to be with respect to the expected value of the informativity, which integrates over the endorsement model's belief distribution:
  $S(u \mid k) \propto \exp{(\lambda \cdot {\mathbb E}_{p\sim P_{k}} \ln{ \int_{\theta} L(p, \theta \mid u)} \diff \theta )}$
  For the empirical case studies described below, these two versions of the model make almost identical predictions.
]
This endorsement model (called $S$ for speaker) does so by reasoning about the interpretation model $L$: 
\begin{equation}
S(u \mid p) \propto (\int_{\theta} L(p, \theta \mid u)  \diff \theta)^\lambda
\label{eq:S1}
\end{equation}

The informational content of the generalization concerns the referent prevalence $p$.
The semantic threshold $\theta$ is a nuisance parameter then; the endorsement model integrates over the interpreter's posterior beliefs about $\theta$.
Finally, because the endorsement model must decide whether or not to endorse the generalization, we assume this model is an approximately rational decision-maker, with degree of rationality given by $\lambda$.
This exponentiation step acts as a soft-max function on $S$'s posterior beliefs of which utterance is better.

<!-- \ndg{this doesn't make a ton of sense in this context, since we haven't set up S as a decision maker....} -->

<!-- We consider the notion of truth judgments or endorsement from the information-theoretic perspective: Would a generalization statement convey the appropriate information to a naive interpreter?  -->

<!-- We formalize this by considering how well the generalization would convey the referent prevalence $p$ to the $Lit$ model (Eq. \ref{eq:L0}). -->

<!-- \begin{equation}  -->
<!-- S(u \mid p) \propto \exp{(\lambda \cdot \ln{ \int_{\theta} Lit(p, \theta \mid u)  \diff \theta } )} -->
<!-- \label{eq:S1} -->
<!-- \end{equation} -->
<!-- \ndg{this eqn isn't well motivated. if we never use cost in this paper, then get rid of exp and ln and just have Lit to a power of lambda. also say why it's called S earlier?} -->

<!-- The endorsement model simulates what the interpretation model would believe upon hearing an utterance $u$: $Lit(p, \theta \mid u)$. -->
<!-- The proportionality in Eq. \ref{eq:S1} implies normalization over a set of alternative utterances.  -->
<!-- We interpret the endorsement task (e.g., "true" vs "false"; "agree" vs. "disagree") as supplying two alternatives: *endorse* or *not*, where *not* we take to be a silent utterance that conveys no information content [@Franke2014cogsci; @Degen2014]: $\denote{null}(x, \theta) = \text{True}$.^[ -->
<!--   This "null" alternative to the generalization can be realized in at least two other ways: the negation of the generalization (e.g., "It is not the case that Robins lay eggs") or the negative generalization (i.e., "Robins do not lay eggs"). -->
<!--   The latter is different because it creates a new threshold (analogous to how "short" and "tall" are modeled with different thresholds). -->
<!--   All results reported are similar for these two alternatives, and we use the alternative of the "silent" utterance for simplicity. -->
<!-- ] -->

Our endorsement model (Eq. \ref{eq:S1}) provides a mapping from the prevalence in the category being referred to (i.e., how many robins lay eggs)---the *referent prevalence* $p$---to an endorsement probability for the corresponding generalization (e.g., "Robins lay eggs"): $S(u = u_{gen} \mid p)$. 
The model assumes a threshold semantics based on probability (prevalence) but does not require specifying the threshold *a priori* (note that there is no $\theta$ in the left-hand side of Eq. \ref{eq:S1}).
This formalism builds on a tradition in formal semantics to try to precisely define the conditions under which a sentence is true or false [@Montague1973].
We go beyond previous semantic models of generics [e.g., @Cohen1999] by embedding our semantic hypothesis (a simple but vague threshold) in a cognitive model in which relevant contextual knowledge can be formalized.
In this simple model, the relevant contextual knowledge is given by a prior distribution over the prevalence $P(p)$.

<!-- By doing so, we are able to describe how context influences generic understanding and are able to make precise, quantitative predictions about human judgments. -->

### Prevalence priors

The literal interpretation of a generalization (Eq. \ref{eq:L0}) reflects a balance between an uncertain threshold and shared background knowledge about the feature in question.
This background knowledge may be richly structured, reflecting intuitive theories about the underlying causes of different kinds of properties [cf., @Leslie2007].
This model posits, however, that the only impact of structured knowledge on truth judgments is in their implications for beliefs about prevalence. 

Prior distributions over prevalence can be revealed by considering the prevalence of the feature in alternative categories.
Think about five of your favorite kinds of animal: What percentage of each of them *are female*? What percentage of each of them *lay eggs*?
Figure\ \@ref(fig:simulations) (row 1) show hypothetical prevalence priors for six different properties.
The *lay eggs* distribution has substantial probability mass near 0 (since many animal categories do not have egg-layers) with a secondary component peaked around 0.5, because among the animals with egg-layers, only the female members of the category have the property.
Conversely, the distribution over the prevalence of *being female* is unimodal and centered at 0.5, because almost all animals have female members in that proportion.

By encoding knowledge about other categories, the prevalence prior distributions are deeply connected to the construct of *cue validity*, or the probability of the kind given the feature: $P(x \in k \mid x \in f)$ (e.g., one's predictions about whether or not an entity is a mosquito, upon learning that it carries malaria).
The strongest view of cue validity is that it operationalizes an alternative hypothesis about the interpretation of generic statements: "Mosquitos carry malaria" means "It is mosquitos that carry malaria". 
In fact, empirically-elicited cue validity has been shown to be highly correlated with endorsements of generics [@Khemlani2012].
Cue validity is "inverse prevalence"; the two are related via Bayes' Rule:
$P( k \mid  f) = \frac{P( f \mid  k) \cdot P( k)}{\sum\limits_{k' \in K} P( f \mid k') \cdot P( k')}$.
Knowledge about other categories $k'$ enters in the denominator.
Indeed this normalizing constant (the denominator) is the expected value (i.e., the mean) of the prevalence prior distribution: $\mathbb{E}[P(p)]$.
Thus cue validity comes from a point estimate of the prevalence prior distribution.
For a more detailed derivation of this relationship between cue validity and prevalence priors, see Appendix A.
For comparison to standard methods in the literature on generics [e.g., @Khemlani2012], we will construct alternative models based on empirically-elicited cue validity.

<!-- The prevalence priors represent abstract beliefs about the properties -->
<!-- To reason through those questions, you may rely upon your intuitive theories of reproduction (e.g., only females lay eggs).  -->
<!-- Each property has a prevalence  -->


<!-- For example, many different kinds of animals *do not bark* (more precisely: have close to 0 exemplars who bark); thus, the prevalence prior for the feature *barks* should have substantial probability mass near 0, because one would expect a randomly-sampled category to have 0 or close to 0 exemplars that bark. -->
<!-- Furthermore, among the categories that do have individuals that bark (e.g., dogs, seals, ...), the probability is quite high that an exemplar will bark; thus, the corresponding prevalence prior would have some probability mass at relatively high prevalences, potentially with some uncertainty (Figure\ \@ref(fig:simulations); column 1). -->
<!-- Abstract beliefs between different kinds of categories could manifest in these prevalence priors in the form of multi-modal distributions; for example, the prevalence prior for *lays eggs* should similarly have substantial probability mass near 0 (since many animal categories do not have egg-layers) but should have a secondary component peaked around 0.5, because among the animals with egg-layers, only the female members of the category have the property (Figure\ \@ref(fig:simulations); column 4). -->


<!-- The uncertain semantic threshold $\theta$ is resolved by the literal interpretation model $Lit$ (Eq. \ref{eq:L0}) the model's background knowledge about the feature in question---the *prevalence prior* $P(p)$---with the uncertain semantics. -->



<!-- Because $P(\theta)$ is assumed to be a uniform distribution across all contexts, a generalization could in principle be felicitous with any referent-prevalence.  -->
<!-- However, the interpretation model's prior beliefs $P(p)$ constrains possible interpretations of the statement, and thus the endorsement.  -->

<!-- Our model makes context-sensitive predictions about endorsing generalizations based on two model components: The prevalence priors $P(p_fk)$ in Eq. \ref{eq:L0} and the referent-prevalence $p$ in Eqs. \ref{eq:S1} and \ref{eq:delta}. -->
<!-- Referent-prevalence is the probability that an individual $x$ of the referent-category (e.g., *dogs*) will have the feature being predicated of the category (e.g., *barks*). -->
<!-- We will return and refine this definition in Case Study 2. -->
<!-- For now, the referent-prevalence is simply a probability that determines the truth-conditional semantics.  -->
<!-- Our hypothesis does not provide a complete mapping from the referent-prevalence directly to endorsement judgments, however, because $\theta$ is underspecified. -->
<!-- These internal models may have domain-specific features but can be described by the domain-general currency of inductive belief: probability. -->





<!-- Since *cue validity* implicitly encodes knowledge of other categories (by summing over $k'$) and the prevalence prior explicitly encodes knowledge of other categories, how are these two constructs related? -->
<!-- In the prevalence prior $P(p_f)$, a category is represented only by its corresponding prevalence (i.e., a sample from the prevalence prior can be thought of as a category $k$, with the only information available about the category being the prevalence of the feature in that category $p$).  -->
<!-- Thus, $P(p) = P(k_{f})$. -->

<!-- cut on 2/9: -->
<!-- The fact that the prevalence prior distribution relates only via its mean value to *cue validity* reveals a potential shortcoming of cue validity: By reducing a distribution to a point estimate, the structure of the distribution is lost.  -->
<!-- This is particularly problematic for prevalence distributions that encode conceptual knowledge via multimodal distributions (e.g., Fig. \@ref(fig:simulations)A; bottom row); the mean of a multimodal distribution is not a good representation of that distribution.  -->
<!-- We return to this point empirically in Case Study 1. -->

<!-- These distributions can be thought of as distributions over categories, displaying only the prevalence for the property in question. -->

<!-- F(left; filled colors) shows six prior distributions over feature-probabilities, representing the relevant background knowledge about each property. -->
<!-- For example,   -->

### Model simulations

The endorsement model defined in the previous section explicitly predicts that the variability in endorsements for generalizations in language can be explained by two factors: (i) the referent prevalence in the category under discussion $p$ in Eq. \ref{eq:S1} (e.g., $P(x \text{ lays eggs} \mid x \text{ is a robin})$) and (ii) the background knowledge about prevalences---the prevalence prior---$P(p)$ (Eq. \ref{eq:L0}).
We simulate how these two factors change both literal interpretation and endorsement using schematic parameter values based on intuition from classic examples in the literature on generic language.
We implemented these and all subsequent Bayesian models in the probabilistic programming language WebPPL [@dippl].
All models, analyses, data and links to experiments used in this paper can be found at \url{https://mhtess.github.io}.

<!-- depends upon the probability that utterance vs. silence accurate conveys to a naive listener a. -->
<!-- This probability of successful communication is given by $L(h \mid u, \theta)$ (Eq. \ref{eq:S1}) and depends upon the listener's *a priori* beliefs about the prevalence in question: $P(h)$ (Eq. \ref{eq:L0}), as well as the referent-category prevalence $h$ (Eq. \ref{eq:S1}). -->
<!-- Predictions for endorsement depend upon how well the listener's posterior on $h$  upon hearing a generalization matches an $h$ that the speaker wants to convey in comparison to how well the listener's prior matches (which would result from the speaker staying silent). -->
<!-- For purposes of illustration, we present different hypothetical priors on feature-probabilities $P(h)$, together with listener $L$ posterior distributions on $h$ after hearing utterances corresponding to (i) the underspecified threshold semantics as well as (ii) a comparison model where the threshold is fixed near-0, corresponding intuitively to the quantifier *some* (Figure \ref{fig:simulations}). -->


```{r loadCachedSimulations, cache = F}
load("cached_results/modelSims-priors_fixedT_uncertainT_speaker.RData") # sims.priors, sims.fixed.thresholds, sims.uncertain.thresholds, s1.simulations.relabeled
load("cached_results/modelSims-uniform_fixedT_uncertainT_speaker.RData") # rs.wp.l0, rs.listener.wp.tidy.samples, rs.tidy


s1.simulations.relabeled.2 <- left_join(
  s1.simulations.relabeled %>%  
    mutate(PriorShape = factor(example, 
                               levels = c("Dogs bark",
                                          "Kangaroos have spots",
                                          "Sharks don't eat people",
                                                      "Robins lay eggs",
                                                      "Robins are female",
                                                      "Mosquitos carry malaria"),
                               labels = c("bark", "have spots", "don't eat people", 
                                          "lay eggs", "are female", "carry malaria")),
              category = c("sharks", "robins", "robins", "kangaroos", "dogs", "mosquitos"),
              xlabpos = c(0.8, 0.5, 0.5, 0.325, 0.85, 0.325),
              ylabpos = c(0.12, 0.25, 0.25, 0.12, 0.12, 0.12)
           ),
                       data.frame(src =  c(rep("Prevalence priors", 6), rep("Interpretation posteriors",6 )),
                                  example = with(s1.simulations.relabeled, c(as.character(example), as.character(example))))
 ) %>%
   mutate(featureProb = ifelse(as.character(src) == "Prevalence priors", featureProb, -99),
          xlabpos = ifelse(as.character(src) == "Prevalence priors", xlabpos, -99))
```


```{r uniformPriorSimulation, fig.cap = "Computational model behavior assuming a uniform prior over prevalence. A: Interpretation model posteriors assuming different fixed thresholds (facets). High thresholds rule out more world-states (prevalence levels), leaving fewer world-states among which to distribute the full probability mass. B: Generic interpretation model averages over all thresholds to return a posterior distribution that favors higher prevalence levels in a graded manner. C: Endorsement model predicts higher rates of endorsemens as prevalence levels increase.", fig.width = 13, fig.asp = 0.3, out.width = "100%", fig.align = "center", cache = F}

fig.l0.thresholds <- ggplot(rs.wp.l0 %>% 
                              mutate(theta = round(theta, 2)) %>%
                              filter(theta %in% c(0, 0.25, 0.50, 0.75)), aes( x = state, 
                                           y = literalPosterior, 
                                       group = theta))+
  geom_line(size = 1)+
  geom_vline(aes(xintercept = theta), 
             color = 'darkred', size = 1)+
  scale_x_continuous(breaks = c(0, 1))+
  scale_y_continuous(breaks = c(0, 0.2))+
  ylab("Posterior probability mass")+
  xlab("Prevalence")+
  facet_wrap(~theta, nrow = 1)+
  ggtitle("Fixed-threshold interpretations")


fig.fullInterpretation = ggplot(rs.listener.wp.tidy.samples %>%
                           mutate(utterance = factor(utterance,
                                               levels=c("null","gen"),
                                               labels =c("silence", "generalization"))), 
       aes( x = support,fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3)+
  scale_fill_solarized()+
  scale_color_solarized()+
  xlab("Prevalence")+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 1.5))+
  guides(fill = guide_legend(reverse = T), color = guide_legend(reverse = T))+
  ggtitle("Uncertain-threshold interpretation")+
  theme(legend.position = c(0.25, 0.8))


fig.endorsement.thresholds <- ggplot(rs.tidy %>%
                           mutate(utt = factor(utt,
                                               levels=c("null","gen"))), 
                         aes( x = state, y = prob, fill = utt, color = utt))+
  geom_col(size = 1, alpha = 0.4, color= 'black')+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ylab("Endorsement probability")+
  xlab("Prevalence (Speaker beliefs)")+
  ggtitle("Endorsement predictions")+
  scale_fill_solarized()+
  scale_color_solarized()+
  guides(fill = F, color = F)

cowplot::plot_grid(
  fig.l0.thresholds,
  fig.fullInterpretation,
  fig.endorsement.thresholds,
  nrow = 1, labels = c("A", "B", "C"),
  align = 'h',
  rel_widths = c(1.5, 1, 1)
)
```


```{r simulations, fig.cap = "Model simulations assuming different prevalence priors. Top: Prevalence priors for six example features. Shapes of the priors were chosen to intuitively correspond to the properties labeling the distributions. Arrows show referent-prevalence for a target category. Bottom: Interpretation model posterior distributions over prevalence upon hearing a generalization about a novel category. Numbers at bottom correspond to endorsement model predictions for endorsing the generalization for  the referent-category whose prevalence is shown in the top facets (e.g., \"Mosquitos carry malaria\").", fig.width = 9, fig.asp = 0.37, out.width = "100%", fig.align = "center", cache=F}

fig.sims.priors <- ggplot(
  bind_rows(sims.priors %>% 
              mutate(src = 'priors'),
            sims.uncertain.thresholds %>% 
              mutate(src = 'posteriors')
            ) %>% mutate(PriorShape = 
                           factor(PriorShape,  
                                  levels = c("barks", "hasSpots", "doesntEatPeople", "laysEggs", "isFemale", "carriesMalaria"),
                            labels = c("bark", "have spots", "don't eat people", "lay eggs", "are female", "carry malaria")),
                         src = factor(src, levels = c("priors", "posteriors"),
                                      labels = c("Prevalence priors", 
                                                 "Interpretation posteriors"))), 
  aes(x = state, fill = PriorShape, color = PriorShape))+
    geom_density(aes(y = ..scaled..), size = 0.6, alpha = 0.7)+
    theme_few() +
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    # geom_rect(data = s1.simulations.relabeled.2,
    #           aes(xmin = featureProb - 0.05, xmax = featureProb + 0.05, ymin = 0.0, ymax = 0.15),
    #           fill = 'black', inherit.aes =F)+
    geom_segment(data = s1.simulations.relabeled.2,
              aes(x = featureProb, xend = featureProb, 
                  yend = 0.02, y = 0.2), size = 1,
              fill = 'black', inherit.aes =F, arrow = arrow(length = unit(0.2, "cm"),
                                                            type = 'open'))+
    geom_label(data = s1.simulations.relabeled.2,
                aes(x = xlabpos, y=0.25, label = category),
                label.padding = unit(0.075, "lines"),
                  family = 'Palatino', fontface = 'bold', size = 3.2, inherit.aes =F, force = 15)+
    ylab("Normalized probability density") +
    xlab("Prevalence")+
    scale_color_solarized()+
    scale_fill_solarized()+
    facet_grid(src~PriorShape, scales = 'free')+
    theme(strip.text.y = element_text(angle = 0, hjust =0),
          legend.position = "none", 
          plot.margin=unit(c(0.5,0.5,1.5,0.5),"cm"))


ggdraw(fig.sims.priors) + 
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Dogs bark"),endorsement))[[1]], 2), 
             0.12, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Kangaroos have spots"),endorsement))[[1]], 2), 
             0.25, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Sharks don't eat people"),endorsement))[[1]], 2),
             0.36, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Robins lay eggs"),endorsement))[[1]], 2), 
             0.48, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Robins are female"),endorsement))[[1]], 2), 
             0.6, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label(round(unique(select(filter(s1.simulations.relabeled.2, example == "Mosquitos carry malaria"),endorsement))[[1]], 2), 
             0.72, 0.12, fontface = "italic", fontfamily = "Times") +
  draw_label("Endorsement Prediction", 0.885, 0.12, size = 10)
```

The literal interpretation model computes a posterior distribution on prevalence by considering different possible thresholds $\theta$.
Figure\ \@ref(fig:uniformPriorSimulation) shows different components of the model behavior assuming a uniform prevalence prior $P(p)$. 
If the threshold were to be very high (e.g., $\theta = 0.75$), only the highest prevalence levels would be consistent with the utterance (Figure\ \@ref(fig:uniformPriorSimulation)A, right).
As the threshold decreases, more and more prevalence levels would be true  (Figure\ \@ref(fig:uniformPriorSimulation)A).
Roughly speaking, the uncertain-threshold interpretation model averages over these possibilities, resulting in a posterior distribution that favors higher prevalence levels because they are consistent with more thresholds (Figure\ \@ref(fig:uniformPriorSimulation)B).
The endorsement model inverts the interpretation model and predicts higher rates of endorsement as the speaker's belief about the prevalence (referent-prevalence) increases (Figure\ \@ref(fig:uniformPriorSimulation)C). 

<!-- This reasoning process favors lower thresholds because they are consistent with more prevalences. -->
<!-- Low thresholds (e.g., $\theta = 0.25$) rule out very few possibilities (only $p \leq 0.25$), and thus an interpretation with a low-threshold still has a lot of uncertainty about the prevalence (Figure\ \@ref(fig:simulations)A, left).  -->
<!-- Higher thresholds  (e.g., $\theta = 0.75$) rule out many possibilities; an interpretation with this threshold has correspondingly less uncertainty about the prevalence (Figure\ \@ref(fig:simulations)A, right). -->
<!-- The flip-side of this is that the endorsement model is less likely to produce an utterance with a low-threshold in mind, because the end result would be, from an information-theoretic perspective, similar to staying silent (a posterior not very different from the prior). -->
<!-- Higher thresholds (e.g., $\theta = 0.9$) rule out more possibilities and thus would be highly informative, but the interpretation model must balance this with the prior probabilities of the prevalences implied by the threshold (Figure\ \@ref(fig:simulations)A).  -->
<!-- The result of this reasoning process is a trade-off between highly informative thresholds and the prior probabilities of the prevalences implied by those thresholds. -->

The uncertain-threshold model's interpretations are highly sensitive to the shape of the prevalence priors (Figure\ \@ref(fig:simulations)).
Hearing "Ks bark" tells the literal interpreter that *almost all* Ks bark, though there is a good deal of uncertainty in the precise quantity (column 1).
"Ks lay eggs" has a strikingly different interpretation: It means "Half of Ks lay eggs" (column 4).
The interpretation model can also derive very weak interpretation, as shown in the  *carries malaria* distribution (column 6).

The endorsement model (Eq. \ref{eq:S1}) predicts endorsement probabilities based on the literal interpretation of the utterance and the referent prevalence (e.g., how many robins lay eggs; shown in arrows in Figure\ \@ref(fig:simulations)A).
Predictions for a few examples are shown in the bottom row of Figure\ \@ref(fig:simulations).
In accord with intuition, the endorsement model predicts "Dogs bark", "Robins lay eggs", and "Mosquitos carry malaria" are all true, despite the referent-prevalences varying substantially between these three examples. 
Intriguingly, the model predicts "Robins are female" (which has the same prevalence as "Robins lay eggs") should receive intermediate endorsement: It is neither true nor false.
To understand this prediction, examine the interpretation distribution for the *are female* property: It is identical with the prior (Figure\ \@ref(fig:simulations); column 5; top vs. bottom row).
The endorsement model decides that is neither better nor worse to produce the generalization than to stay silent, as they both carry the same information content.
This example can be contrasted with cases such as "Sharks don't eat people" and "Kangaroos have spots", which the model thinks would be misleading to say (i.e., better to say nothing).

These simulations show how the model predicted endorsement depends upon the background knowledge of the interpreter about the property $P(p)$ as well as the referent-prevalence $p$ presented to the endorser. 
We chose schematic values for each of these, and saw that the endorsement model recovers standard intuitions about the truth or falsity of classic examples from the generics literature.
In what follows, we test this theory for a wide range of generalizations, including generalizations of different types (categories, events, and causes).
We do this by both measuring and manipulating background knowledge and referent-prevalence and predicting human endorsements of generalizations.

<!-- The literal interpretation of a generalization about a previously unknown category (e.g., "Feps bark.") is given by Eq. \ref{eq:L0} and shown in  -->

<!-- The lighter distribution is the interpretation distribution given by Eq. \ref{eq:L0}.  -->
<!-- For instance, the interpretation of a generalization about the property \textsc{barks} is that the prevalence is quite high, near 1 with some uncertainty (top left; lighter pink distribution). -->
<!-- This would correspond to a rather strong interpretation (i.e., "Almost all feps bark"). -->
<!-- This is not the case for the \textsc{lays eggs} distribution (a la "Feps lay eggs"; bottom left, green).  -->
<!-- Given the background knowledge about that property----not that many animals lay eggs, and among those for which the feature is present, the probability is about 0.5 (because it's only present in the females)----the interpretation is much more conservative: "About half of feps lay eggs". -->
<!-- The model can even derive very weak interpretations, as is shown in the \textsc{carries malaria} distribution (bottom right, purple). -->
<!-- Again, the literal interpretation depends upon the background knowledge in a deep way. -->

<!-- The endorsement model's predictions for six generic sentences are shown in Figure\ \@ref(fig:simulations) (right). -->
<!-- Given a referent-prevalence $h'$ (e.g., $P(x \text{ lays eggs} \mid x \text{ is a robin})$; Fig.\ \@ref(fig:simulations) right x-axis) and the background knowledge of the interpreter (Fig.\ \@ref(fig:simulations) left), the endorsement model (Eq. \ref{eq:S1}) predicts an endorsement probability (Fig.\ \@ref(fig:simulations) right y-axis). -->
<!-- We see the model correctly  -->


<!-- \mht{For further discussion about the behavior of the model, and these six examples, see Appendix?} -->



<!-- that the behavior of the uncertain-threshold semantics is distinct from both the prior distribution over probability $h$, as well as the inferences derived from a fixed-threshold semantics. -->
<!-- For these simulations, we had specify both the prevalence priors $P(h)$ and the referent prevalence $h'$.. -->
<!-- In the rest of this paper, we both meausure and manipulate $P(h)$ and examine the behavior of the speaker model in three case studies: generalizations about categories, events, and causes. -->

<!-- These different semantic models make different predictions easily seen when considering a uniform prior distribution over $h$ (Figure\ \@ref(fig:simulations); top row). -->
<!-- The fixed-threshold model rules out only the lowest possible feature-probabilities ($h \sim 0$) and returns a posterior very similar to the prior. -->
<!-- The behavior of the generalization is distinct from a fixed-threshold model: The higher the prevalence $h$, the more likely it is after hearing the generalization.^[ -->
<!-- The intuition behind the model's behavior can be gleaned by imagining what the listener model $L$ would believe given different thresholds, and averaging over those possibilities. -->
<!-- If the threshold $\theta$ is very high, only the highest prevalence $h$ would pass the threshold. -->
<!-- If the threshold $\theta$ is slightly lower but still high, the highest prevalences $h$ would still pass the threshold, as would some that are slightly lower. -->
<!-- As the threshold $\theta$ takes on lower and lower values, more and more $h$'s would surpass it. -->
<!-- When $\theta$ is very low, almost all $h$ are consistent with it (akin to fixed-threshold model). -->
<!-- The listener averages over these possibilities: $h$'s with higher values pass more thresholds and the result is that higher $h$'s are more likely *a posteriori*. -->
<!-- ] -->

<!-- Next, we consider a few classic cases from the literature on generics to demonstrate the kind of inferences our listener model would draw from different generic statements. -->
<!-- The strength of a listener's inference about $h$ (i.e., how prevalent is the feature?) depends in systematic ways on the prior belief distribution over $h$. -->
<!-- In Figure\ \@ref(fig:simulations) (row 2), we show a schematic prior distribution that is bimodal with peaks near 0\% and some high prevalence values; this prior could be over the prevalence of *barking* because many kinds of creatures do not bark (i.e., have $h \sim 0$; e.g., cats), but *for those that do have members that bark*, many of them bark (i.e., have some high $h$). -->
<!-- The fixed threshold model (right column) struggles to differentiate those that generally do not have the feature from those that usually have the feature, returning a posterior distribution very similar to the prior.^[ -->
<!-- We model "those that do not generally have the feature" as a Beta distribution with an expected value (mean) close to zero.  -->
<!-- The fact that this component of the prior is not just a Delta function at 0\% reflects the intuitive possibility that some members of a kind who do not generally have the feature (e.g., a cat who barks) could somehow acquire the feature from accidental or transient causes (e.g., a strange genetic mutation). -->
<!-- ] -->
<!-- The uncertain threshold model, however, easily rules out the categories that do not generally have the feature and strongly signals the property is widespread in the category. -->

<!-- How does the model handle the puzzling case of "Robins lay eggs" vs. "Robins are female"? -->
<!-- In each case, we must consider the prevalence prior:  $P(h_\text{lay eggs})$ and $P(h_\text{are female})$. -->
<!-- For being female, no matter what animal category a person might think of, the feature is prevalent in the exact same proprotion (i.e., 50\% of X are female; Figure\ \@ref(fig:simulations) bottom row). -->
<!-- For laying eggs, it really depends: If a person thinks of a falcon, then 50\% of that category lays eggs; if a person thinks of a bear, then 0\% of them lay eggs. -->
<!-- This dependency is reflected in the corresponding $P(h)$, which is a bimodal distribution with peaks near-0\% and near-50\% (Figure\ \@ref(fig:simulations) row 3). -->
<!-- For both priors, the interpretation upon hearing the generalization is the same (i.e., roughly 50\% of the category has the feature; Figure\ \@ref(fig:simulations) rows and 5, middle red panel). -->
<!-- The difference in endorsement comes from the comparison to the prior: For being female, the listener is very likely to arrive at 50\% under her prior, but for laying egges, this is not the case.  -->
<!-- In other words, "Robins are female" has little very informational content as the listener's posterior is nearly identical with her prior (i.e., it doesn't matter if the speaker says the generalization or stays silent). -->
<!-- "Robins lay eggs", however, has a lot of informational content. -->

<!-- Finally, we look at how the uncertain threshold produces an interpretation for the statement "Mosquitos carry malaria", which intuitively should correspond to "Some mosquitos carry malaria". -->
<!-- The prior $P(h_\text{carry malaria})$ assumes that most creatures do not carry malaria and among those that do, the feature is not very widespread. -->
<!-- Here, we see that listener's posterior upon hearing the generalization (the uncertain threshold) is similar to what she learns upon hearing "Some mosquitos carry malaria" (the fixed threshold; Figure\ \@ref(fig:simulations) row 4).  -->
<!-- Thus, a speaker who believes that *very few* mosquitos carry malaria will still endorse "Mosquitos carry malaria". -->


```{r child = 'case1-generics.Rmd'}
```

```{r child = 'case2-habituals.Rmd'}
```

```{r child = 'case3-causals.Rmd'}
```

# General Discussion

The human species is remarkable not only because we can extract useful generalizations from observations of the world, but because we can convey these generalizations to each other succinctly using language.
Generalizations expressed in language (e.g., "John runs.", "Dogs are friendly.", "Fire causes smoke.") are a premier example of how simple statements---statements understood by even the youngest language users---can convey subtle meanings and display complex sensitivities to context.
We have argued that the core meaning of such linguistic expressions can be understood by a vague threshold function that operates over a speaker's inductive beliefs, formalized in terms of predictive probability or *prevalence*.
Critically, deploying this simple semantics within a formal framework for pragmatic language understanding leads to complex interactions with background knowledge.
<!--
formalize their meaning by appealing to prevalence, which we define as a predictive probability (as opposed to frequency).
As a formal theory of the language of generalization, our framework unifies large swaths of language about distinct semantic types, illustrated here with categories, events, and causes.

Generalization underlies each of these, and we formalize their meaning by appealing to prevalence, which we define as a predictive probability (as opposed to frequency).
-->
We tested this theory by exploring its implications for truth judgments, modeled as a speaker's decision about whether it would be useful to utter the generalization. 
Endorsement, we have shown, depends in systematic ways on the listener's prior beliefs about prevalence.
This framework accounts for a number of philosophically puzzling generic statements (Expt. 1), naturally extends to other domains of generalizations (habituals and causals; Expts. 2 \& 3), and provides an avenue for top-down moderators on language use by way of predictive probability (Expt. 2c).
We have provided strict tests of our formal model by both measuring and manipulating listeners' background knowledge as well as comparing our model to a number of alternatives.
In each case, our model provided a strong quantitative fit to human judgements while other models fall short.

Our model leverages the insights of truth-functional semantics and computational cognitive modeling to articulate how an agent should update their beliefs based on a generic sentence. 
The Bayesian model provides a clean separation of the semantics of a generalization (represented formally by a threshold-function) from world knowledge (represented by the prevalence prior).
Previous theoretical accounts have either aimed to account for the context-sensitivity of generics by positing distinct semantic constructs [e.g., *relative* vs *absolute* generics, described below; @Cohen1999] or positing a semantics that cannot be separated from world knowledge [@Leslie2008].
Here, we demonstrate how the context-sensitivity of generics can emerge via the interplay of a stable (but vague) semantics and diverse background knowledge. 

<!--
NDG: i cut this from below...
This paper puts forth the theory that the language of generalization communicates predictive probabilities from speaker to hearer.
These predictive probabilities are not observable frequencies, the object of other statistical approaches to generics, but mental representations.
Probabilities encode predictions about the future and are subject to top-down moderation (e.g., by way of intuitive theories).
Predictions about the presence of a feature can be the result of beliefs about internal causes of the feature [e.g., in an essentialist view of natural kinds; @Gelman2003], generative kind representations [@Prasada2009], or merely correlational happenstance.
What matters for their influence on generic endorsement, however, is their influence on subjective, predictive probability or *prevalence*.
-->

Communicating probabilities might seem contrary to the long attested failures in reasoning about probability [@Tversky1974].
Our theory suggests that the problems with understanding probabilities observed in classic, cognitive psychology paradigms are a problem in understanding explicit probabilities expressed using *numerical language*, a historically quite recent innovation [cf., @Levinson1995]. 
Rather than conveying probabilities explicitly, generalizations convey them implicitly.
In other words, we argue that the utterance "70% of birds fly" is a precise statement about how many birds fly in the way that "John is 6'3"" is a precise statement about the height of John, whereas "Birds fly" is a vague statement more akin to utterance "John is tall".
The latter statements are easier to process, understood at an earlier age, and may be more useful for human reasoning. 
Indeed, young children are actually quite good with reasoning about probabilities, but in ways that are not explicit or tied to the numerical language of probability [@Xu2008; @xu2009statistical].

<!--
\mht{unsure about this paragraph... a version of it may be better for the cover letter (if at all)}
\ndg{yeah, this is unecessarily inflamatory. ax it.}
Even the most influential of extant theories generally makes one or a few predictions about "different kinds" of generics, and leave it to intuition to decide for a particular generic statement, what kind of generic it is.
In this paper alone, our theory has made hundreds of predictions about the endorsement of individual generic statements, with high accuracy, derived from a general theory that we posit applies to all generic statements.
In addition, previous accounts are rarely general enough to include generalizations of different semantic types (e.g., *habituals*) and deal only with generics.
For these reasons alone, our account is novel. 
-->

In the rest of this discussion, we elaborate how our model relates to language understanding more generally, sketch its application to several philosophical puzzles in genericity, and situate our theory with respect to extant theories of generic language.



<!-- Thus, in addition to expressing a precise hypothesis about the truth conditions of generics, instantiating it in a cognitive model opens up the possibility of building more elaborate models that learn abstract, generalizable knowledge from language. -->

<!-- We note that regressions model that take into account the referent prevalence and the distinctiveness of the feature (e.g., cue validity) do reasonable jobs at explaining some of the variance in the endorsement data. -->
<!-- These kinds of model, however, do not represent bonafide theories of the semantics of generalizations; they are merely a re-description of the data. -->
<!-- <!-- \ndg{this point is unclear. maybe save it for general discussion?} -->
<!-- A theory of the semantics of a generalization must formalize the conditions under which the generalization is true or false as well as how those truth-conditions relate to endorsement.  -->
<!-- That is precisely what our information-theoretic model does. -->
<!-- xx -->
<!-- The formal Bayesian model we articulate provides a clean separation of the semantics of a generalization from world knowledge. -->

<!-- That is, we provide a route for precise quantitative influence of world knowledge on generic language by way of shared background knowledge between speakers and listeners, which at its base takes the form of a prevalence prior. -->
<!-- Our communicative framework also includes a model of a listener who interprets generalization. -->
<!-- Such a quantitative model makes further predictions about domain-general learning from the language of generalization, which we leave for future work.  -->



<!-- \mht{let me know where, if anywhere, we should mention "double generalizations" (e.g., generics about habitual properties)} -->

<!-- \ndg{ -->
<!-- [these paragraphs were out of place here. perhaps incorporate later...] -->
<!-- } -->
<!-- Our model formalizes a simple meaning for generalizations and investigates the structure of world knowledge that could give rise to the context-sensitivities observed in the data. -->





<!-- Our separation of world knowledge from the semantics of generics provides a substantial, but well-circumscribed role for conceptual structure to influence generic production and comprehension. -->
<!-- We do this without having to posit that conceptual structure and semantics are one in the same. -->
<!-- This is makes it possible to connect with theories of formal semantics as well as applied Natural Language technologies that seeks to draw inferences from information conveyed in generalizations in text [e.g., @Herbelot2011]. -->
<!-- Statistical accounts in particular [@Cohen1999; @Nickel2008] -->

<!-- @Nickel2016 notes that genericity is particularly challenging to study because it intersects with many other phenomena in natural language (e.g., gradable adjectives in "Giraffes are tall"). -->
<!-- We agree, and add to this that genericity intersects with *world knowledge* in subtle ways, and it is critical to accurately describe and measure world knowledge before making claims about the semantics of a generalization. -->
<!-- We used the most basic tests to validate our model: Production was examined in terms of *endorsement*, which can be seen as a special case of production when the only available alterantive utterances are the assertion or its negation. -->
<!-- Comprehension was examined in terms of *implied prevalence*, which in our theory is most basic inference a hearer can make upon hearing a generalization. -->
<!-- Though these are highly abstracted tests of the model, the modeling framework in principle allows for elaboration to a more complete production and comprehension model.  -->
<!-- The model is a communicative model, which includes a component corresponding to *comprehension* of genericity (i.e., a listener model).  -->

<!-- We conclude by sketching out arguments for other known philosophical puzzles in genericity. -->

<!-- Implicit aspects of language use: The comparison class and question under discussion -->

<!-- to explore when and how people choose to communicate their abstract knowledge when they have more options than in a two-alternative forced-choice task. -->
<!-- The view of our endorsement model as a minimal communicative model highlights aspects of our modeling approach for further future development.  -->


<!-- ## Generic Identification -->

<!-- Throughout this paper we treated the bare plural construction as a generic utterance with a threshold semantics: $\denote{\text{K F}}(x, \theta)=x>\theta$. -->
<!-- The bare plural construction can also indicate a specific plural predication. -->
<!-- For example, "Dogs are on my lawn" picks out a specific group of dogs, while "Dogs have fur"  does not [@Carlson1977]. -->
<!-- The problem of \emph{identifying} a generic meaning from a bare plural construction is itself a challenging problem because generic meaning can be signaled using a diverse array of morphosyntactic cues. -->

<!-- @Declerck1991 suggests that generic and non-generic bare plurals can be treated in the same way, and that pragmatic considerations alone may resolve interpretative differences. -->
<!-- Indeed it does appear that knowledge of the properties under discussion (e.g., the state of being on a front lawn; the state of having fur) could facilitate the generic identification process. -->
<!-- Other pragmatic factors, like knowledge of the identity of the speaker (e.g., a teacher vs. a veterinarian), can also disambiguate generic and non-generic meaning [@Cimpian2008]. -->
<!-- Recent work suggests that utterances that fail to refer to specific entities or events could pragmatically imply generic meaning [@Crone2016cogsci]. -->
<!-- Incorporating these insights about generic identification into an information-theoretic, communicative perspective is a natural extension of this work. -->




<!-- Expts. 2c \& 2d that showed using participants' *predictions* about the future as the object of communication in our formal model perfectly tracked habitual endorsement, when the present frequency would make the wrong prediction. -->


<!-- One might also question the feature of our computational model that the speaker is explicitly trying to communicate $h$, her subjective probability.  -->
<!-- We note that if the prevalence prior is structured, as we have argued throughout, then the Question Under Discussion that our speaker model is addressing can also be formalized to be "What component of the prior does the referent-category belong?". This model with a modified QUD makes almost identical quantitative predictions as the simple model without this abstract QUD.  -->

<!-- ### The Problems with Communicating Generalizations -->

<!-- Thus, in order to define a generalization about a category, there must be some corresponding concrete particular instance of that category from which the generalization is formed.  -->
<!-- For example, if an agent observes $n$ instances of \textsc{dog} ($d_1, d_2, ..., d_n$) -->
<!-- For example, if an observer forms a generalization about \textsc{dogs}, she must some way of determining when she is in an instance of the category \textsc{dogs}: She must be able to *individuate*. -->
<!-- In Hume's words, generalizations are predictions about "instances of which we have had no experience resemble those of which we have had experience" [@HumeTHN]. -->

<!-- Generalizations can be made about almost anything. -->
<!-- Here, we restrict our focus to generalizations about categories (whose linguistic expression is known as *generic language*), which have been the primary focus of psychologists, linguists, and philosophers. -->
<!-- We posit that our analysis should expect to generalizations about events (habitual language) as well as generalizations about causal forces (causal language). -->

<!-- Generics express a relation between a kind K (e.g., \textsc{robins}) and a property F (e.g., \textsc{lays eggs}), such that the property can also be said to be applicable of an individual (i.e., the bird in my backyard lays eggs). -->
<!-- Bare plural statements (e.g., \emph{Robins lay eggs}) tend strongly to yield a generic meaning [@Carlson1977], though other forms can express such a meaning sometimes (e.g., \emph{A mongoose eats snakes.}). -->

<!-- Given that generics express a property that can be applied to individuals, it would seem intuitive that the number of individuals with the property would be what makes the statement true or false. -->
<!-- Counter-examples like \emph{Mosquitos carry malaria} and \emph{Birds lay eggs} v. \emph{Birds are female} stifle such intuition.  -->

<!-- ### Statistical Accounts of Generics -->

<!-- Statistical accounts take the \textbf{property prevalence} to be fundamental: \emph{Birds lay eggs} means \emph{Birds, in general, lay eggs}.  -->
<!-- Of course, birds do not in general lay eggs (it's only the adult, female ones that do). -->
<!-- The primary way of dealing with such issues is to posit domain restrictions ("implicitly, we are only talking about the females") when there are "salient partitions" [@Carlson1995]. -->
<!-- The most fully-developed theory on this front is due to @Cohen1999.  -->
<!-- Let's first introduce some notation: -->

<!-- ### Conceptual Accounts of Generics -->



## Prevalence priors and conceptual knowledge

Our theory assumes that listeners and speakers share relevant background knowledge (at least in the form of a *prevalence prior*) against which generalizations are interpreted.
In our modeling work, we found that prevalence prior distributions were well-modeled by a mixture-model with two mixture components.
Such a prior distribution implies categorical distinctions between different kinds of categories, perhaps by virtue of having (or lacking) certain causal mechanisms that can bring about the target feature.
Actual conceptual knowledge, needed to interpret generalizations, is most likely richer than our simple two-component prevalence distributions.

Conceptual structure, including higher-order abstractions, can be formalized in probabilistic causal models [@pearl1988probabilistic; @Gopnik2003theory] and their generalization in probabilistic programs [@Goodmanconcepts].
We believe such probabilistic concept representations can be adopted as a formal analog to intuitive theories of natural kinds [@Gelman2003; @Keil1992].
We do not assume a particular view of natural kinds in our model, but note that viewing natural kinds as richly structured categories with clusters of non-obvious properties is compatible with our information-theoretic communicative model. 
The important commonality among different domain-specific background theories is that they each have a statistical aspect (supporting prediction via beliefs about prevalence), which language can interface with.
Thus, our theory provides a separation between conceptual knowledge and the semantics of generalizations; the interface between the two is predictive probability or *prevalence*. 

The fact that conceptual knowledge is not a part of our formal semantics does not imply that such knowledge is peripheral to communicating with generalizations.
Not only does conceptual knowledge influence interpretation via prevalence priors, but it may very well be what the speaker intends to communicate.
Like other probabilistic pragmatic models, our model distinguishes the semantic contribution of an utterance (what enters into the truth-functional semantics) from a speaker's utility in producing that utterance. 
For simplicity, the model presented here assumes these two are the same: the speaker's utility comes from conveying prevalence. 
However, the model makes nearly identical predictions if the speaker's utility comes from communicating the abstract parameters of the prevalence distributions [e.g., if the speaker intends to convey that "K is the kind of thing that Fs"; cf., @Prasada2006].
This observation may prove useful for constructing models of teachers, whose goals include conveying abstract relations between kinds and properties.

<!-- The model, however, has the flexibility to address richer communicative goals [also known as the *Question Under Discussion* or QUD; @roberts1996qud]. -->


<!-- Future work should investigate formalizations of attested differences in background knowledge about properties [e.g., @Prasada2013's *principled*, *statistical*, and *causal* connections] and their corresponding influence on generic endorsement via prevalence priors.  -->




<!-- \ndg{ [why is this par here. and what does it mean??] -->
<!-- The rational model of communication that we have developed in this paper makes explicit a speaker's assumptions about the goals of communication, sometimes referred to as the *Question Under Discussion* or QUD [@roberts1996qud].  -->
<!-- Richer communicative contexts will surely need to elaborate the QUD to fit more appropriately with the informational goals of the context in which generalizations are produced. -->
<!-- This observation is promising for the future goal of integrating communicative goals about kinds or conceptual structure into the information-theoretic communicative framework presented here. -->
<!-- } -->

<!-- Primarily investigated through generic language (category generalizations), this perspective holds that generics are the linguistic outlet of the mind's default mode of representing kinds [@Leslie2007] and "...an adequate account of the meanings of generic sentences requires an understanding of the ways in which we represent connections between kinds and properties [p.406; @Prasada2013]." -->
<!-- @Prasada2006 and later @Prasada2013 distinguish properties that have *principled connections* to kinds, *statistical connections*, and *causal connections*.  -->


<!-- Leslie suggests information that is striking (e.g., "Tigers eat people") is ecologically useful and thus permitted to be a generalization, even if the property is not widespread. -->
<!-- Prasada has argued that *characteristic* properties (e.g., "Diapers are absorbent") and *statistical* properties (e.g., "Diapers are white") are  -->
<!-- Gelman outlines how generics tend to express *essential* qualities that are relatively timeless and enduring.  -->
<!-- Where in the probability-based semantics could such conceptual distinctions come into play? -->

<!-- Inferential role semantics -->
<!-- We take the view the causal relations only does anything because it implies statistical regularities, and these statistical regularities are what our linguistic model depends on. -->

<!-- - what are habituals like under Leslie? -->

<!-- probabilistic treatment of kinds vs. of causality -->
<!-- conceptual representation vs. causal structure -->

<!-- rational rules: concepts are relatively definitional (with some probabilistic structure on those definitions) -->
<!-- - leslie: my kinds are your probabilistic concept representations -->
<!-- - the reason why particular generics are licensed. not that there are kinds and that generics communicate about them. -->
  <!-- - fundamentally communicative element to what the prevalence is and why a generic would sound good in a praticular case (information relative to the prevalence prior) -->
  
<!-- - Ellen: causality implies a mechanism, not just a statistical relation. -->
<!-- - are there parts of the  -->
<!-- - essentialism: different generative models that imply the same statistics with different causal relations (but orthogonal) -->


## The comparison class

The probabilistic communicative model we introduce in this paper assumes shared background about the statistics of an event or property in question, represented by the prior belief distribution over the prevalence $P(p)$.
We constructed prevalence priors for a property, event, or cause by considering *other possible* categories having the property, people doing the action, or causes producing the effect.
In Expt. 3, we empirically demonstrated the influence of other categories on endorsement of generalizations.
Collectively, these other kinds, people, or causes form *comparison classes* against which the referent-category is evaluated.
Thus, the prevalence prior $P(p)$ is actually a conditional distribution constructed with respect some comparison class $C$: $P(p \mid C)$.

The existence of comparison classes is uncontroversial in the study of *vague* or *underspecified* language [e.g., gradable adjectives like *tall* and vague quantifiers like *many*; @Bale2011; @Solt2009].
Adult judgments of the felicity of gradable adjectives like *tall* or *dark* depend upon fine-grained details of the statistics of the comparison class [@Qing2014; @Schmidt2009; @Solt2012] in ways directly analogous to the context-sensitivity highlighted here for the language of generalizations.
An important problem for comparison classes for both gradable adjectives and generalizations is that the comparison class often goes unsaid (e.g., "John is tall for a person" is often produced as just "John is tall"; "Robins lay eggs relative to other animals" is just "Robins lay eggs").
Recent empirical and computational modeling work suggests that pragmatic reasoning combined with world knowledge can flexibly adjust the comparison class to appropriately suit the context [@Tessler2017].
In this paper, we do not include such a mechanism in our model; instead made the comparison class clear to participants in order to study the remaning context-sensitivity of generics.

<!--
[NDG: i cut this because it is unecassary speculation.]
Uncertainty about the comparison class adds yet more opportunity to the language of generalization for disagreement, miscommunication, or deceit.
Even if interlocutors roughly coordinate on a particular comparison class (e.g., agreeing that they are talking *relative to other animals*), they may fail to coordinate on the prevalences for other categories in the comparison class.
That is, our model makes the prediction that the acceptance or rejection of controversial statements (e.g., "Muslims are terrorists") depends upon a speaker's beliefs about how often other categories exhibit the property (e.g., neo-nazis committing acts of terrorism).
Understanding the contextual influence on the construction of comparison classes should provide insight into failures of communication.
\mht{ellen: TRUE,  I AGREE WITH YOU AND THIS IS PROBABLY OKAY.  BUT IT THINK IT WOULD BE BETTER TO SAY SOMETHING SUBSTANTIVE;  FOCUSSING ON HOW KNOWLEDGE OF THE COMPARISION CLASS SHOULD PROVIDE INSIGHTS INTO FAILURES TO COMMUNICATE SUCCESSFULLY.}
-->

The comparison classes used in our case studies were constructed with respect to the category (*other animals*, *other people*, *other possible causes*).
Thus, our endorsement model assumes that the goal of communication, sometimes referred to as the *Question Under Discussion* or QUD [@roberts1996qud], was to address the question of "*what* has this feature?".
Were the QUD to be reversed (e.g., "what features does the category have?"), the comparison classes would be constructed with respect to the feature (e.g., *other features*, *other actions*, *other effects*).
It has long been noted that the same generalization can be used to address multiple QUDs [@KrifkaGenericBookFocus], and we posit that differences in interpretation are the result of multiple distinct comparison classes competing for influence.
Prosodic focus can change the interpretation: "*Lawyers* care about the law." suggests a category-wise comparison class perhaps in a pedagogical context (i.e., "Lawyers *(as opposed to doctors, firefighters, ...)* care about the law.") while "Lawyers care about *the law*" suggests a feature-wise comparison class perhaps produced by a sardonic speaker (i.e., "Lawyers care about the law *(as opposed to justice, doing what is morally right, ...)*").
Pragmatic reasoning is likely relevant here as well [cf., @Declerck1986; @Tessler2017].
In this work, we focused on category-wise comparison classes purely for methodological convenience.
Future work should investigate the factors that give rise to feature-wise interpretations of generalizations, how the relevant comparison classes are constructed, and how these inferences interact with threshold inference.


<!-- Thus, we conclude generic, habitual, and causal language can be seen as a special case of *vague language*.  -->
<!-- The construction of a comparison class adds another layer of flexibility into the use of generalizations in language. -->
<!-- Objects can be conceptualized and categorized in multiple ways, giving rise to multiple, logically-possible comparison classes (e.g., a robin is a bird, is an animal, is an object).  -->
<!-- We have begun doing work investigating how pragmatic reasoning can help constrain this open-ended problem [@Tessler2017]. -->


<!-- ### Question under discussion -->



<!-- However, the choice in constructing a comparison class can be thought of as the result of addressing a particular QUD. -->
<!-- The QUD is thus another layer of flexibility that makes understanding generalizations so challenging. -->
<!-- In the minimal contexts employed in our experiments, this is a reasonable assumption. -->
<!-- There is a different assumption we could have made, however: Another clear way to construct the comparison class is with respect to other features.  -->
<!-- This *feature-wise* comparison class would correspond to addressing the implicit QUDs: *what does \textsc{person} do?*, *what effects does \textsc{cause} bring about?*, and *what features does \textsc{kind} have?* -->



<!-- Throughout our experiments in this work, we have focused on sentences about animals.  -->
<!-- In addition to being the main focus of past theoretical and empirical work, focusing on animals is methodologically convenient as the comparison class for generics about animals is quite naturally \emph{animals}. -->
<!-- When we look beyond generics about animals, deciding what goes into a comparison class becomes less clear. -->
<!-- There are some hints that the comparison class can be derived with respect to the property [@Keil1979], but may involve pragmatic reasoning as well. -->
<!-- For example, the statement "iPhones are useful" could be in comparison to other forms of technology (like a desktop computer), while "iPhones are heavy" could really only be informative relative to other handheld devices. -->

<!-- The incorporation of a comparison class into the study of generic language might help elucidate other puzzles concerning generics. -->
<!-- Recent work in philosophy and linguistics, for instance, suggest generic language is context-sensitive [@Nickel2008; Sterken2015]. -->
<!-- @Nickel2008 points out that \emph{Dobermans have floppy ears} may be true in the context of a discussion of evolutionary biology but that \emph{Dobermans have pointy ears} is true in a discussion of dog breeding. -->
<!-- Our theory provides a hint from where to begin to understand this context sensitivity: the comparison class. -->
<!-- Different conversational contexts could bring to mind different comparison classes, in a way analogous to the context-sensitivity of  gradable adjectives (e.g., \emph{tall}).  -->
<!-- Hearing that "Abigail is tall" means different things is Abigail is 20 years old or if she is 4.  -->
<!-- Future work will be needed to explore whether a pragmatic inference approach is also relevant to establishing the comparison class, and what background knowledge about properties, categories, and context is relevant. -->




## Acquiring the language of generalization

<!-- The linguistic outlet for generalizations about categories---so called, *generic language*---has received tremendous attention from psychologists, linguists, and philosophers. -->
<!-- Generic language is one of the earliest emerging forms of complex, compositional language. -->
<!-- Somewhere between two and three years of age, children recognize that generics convey a generalization about a category, not directly tied to concrete instances in a scene [@Cimpian2008]. -->

Perhaps the most surprising aspect of the language of generalization is how difficult it is to formalize, given how common it is in child-directed and child-produced speech [@Gelman1998; @GelmanEtAl2004].
<!-- from a formal perspective is that generic language is far from trivial to characterize.  -->
<!-- Generalizations are common in child-directed and child-produced speech [@Gelman1998; @GelmanEtAl2004] and are believed to be central to the growth of conceptual knowledge [@Gelman2004], -->
Generics are often contrasted with quantifier language (e.g., "some", "most", "all", ...), which is, more difficult for young children to acquire [@Brandone2014; @Gelman2015], but easier to formalize.
<!-- If generics convey something about the probabilty of a feature, we would expect them to be in some way comparable to quantifier statments (e.g., "some", "most", "all", ...). -->
<!-- The extreme flexibility of generic meaning (e.g., "Birds lay eggs" vs. "Birds are female") stands in stark contrast to its early emergence in development. -->
<!-- In fact, quantified statements, whose formal meaning is much more straight-forward (e.g., "Some" means more than zero), emerge *later* in development [@Brandone2014; @Gelman2015], and are often confused for generic statements [@Leslie2012a]. -->
This asymmetry between the simplicity of the formal theory and the age of acquisition has led some to conclude that the normal tools for describing the semantics of quantified utterances (i.e., truth-functional notions) are inappropriate for generics [@Leslie2008].

Rejecting the tools of truth-functional semantics for generalizations would be throwing the baby out with the bathwater.
With some reasonable assumptions about the hypothesis space of semantic meanings, the acquisition of a threshold-based truth-functional meaning $\denote{u}(p, \theta) = \{p :p > \theta\}$ requires learning three distinct aspects of meaning: 
(1) the *dimension* being described (i.e., prevalence $p$),
(2) the *polarity* of the relation (i.e., $>$ vs. $<$), and 
(3) the value of the *threshold* (e.g., $\theta = 0$ for "some", $\theta = 0.5$ for "most").
Upon acquiring the dimension and the polarity, a rational learner should represent uncertainty over possible thresholds $\theta$.
Upon repeated cross-situational data with quantifiers, this prior could be updated towards acquiring a fixed meaning.
However, for generics, no fixed threshold is required; the language of generalization is learned once aspects (1) and (2) are understood.
Thus, under our framework, generics should not only be learned before quantifiers but also faciliate the acquisition of quantifiers.
<!-- In our model, $\theta$ is left underspecified in the semantics and is inferred in context. -->
<!-- This informal analysis predicts that a child would first acquire the language of generalizations, and from that, carve out more precise meanings for quantified language, consistent with the developmental data. -->

There is a secondary argument for why our semantics presents an easy learning problem.
<!-- The uniform prior over the threshold $\theta$ in the truth-functional semantics (as we have assumed in our model) provides a secondary argument for why acquiring our semantics for generics should be easy. -->
We have assumed the truth functional threshold $\theta$ comes from a uniform distribution over the unit interval $[0, 1]$, which is mathematically equivalent to a *continuously-valued* or *soft semantics* wherein the degree to which the utterance is true is proportional to the degree itself, in this case prevalence $p$: $\int_{0}^{1} \delta_{p > \theta} \diff \theta = p$.
The model for generic interpretation (Eq. \ref{eq:L0}) then becomes: $Lit(p \mid u) \propto p \cdot P(p)$
This *soft semantics* (corresponding intuitively to a meaning like "the higher the probability, the better", or simply "more is better") is perhaps the simplest quantitative semantics one could posit.
The difficulty in acquiring the meaning of quantifiers, then, is a difficulty in recognizing a fixed-threshold semantics as a special case of this *more is better* semantics.
We leave for future work the precise implementation of such an acquisition model.

## Relationship to other semantic theories


<!-- The study of what makes generalizations true or false then reduces to a study of concepts [@carlson2009concepts] and kind--property relations [@Prasada2013]. -->

<!-- Yet, purely arbitrary relationships can also result in true generalizations [@Nickel2008; @Nickel2016; @Sterken2015]. -->
<!-- <!-- "Cars have tape decks" is a generalization that was true about thirty years ago, but  -->
<!-- <!-- Barns are red" because barn-owners tend to paint their barns red; were barn-owners to decide tomorrow to switch to blue, then "Barns are red" would be false. --> 
<!-- Ravens and toasters have no privileged relationship to each other and to assess if "Ravens are bigger than toasters", we should actually measure the distribution of sizes for ravens and toasters. -->
<!-- An understanding of generalizations just in terms of conceptual relations must be supplemented with the proviso that, in some situations, the actual statistics of the feature matter for making generalizations true. -->

<!-- The alternative approach to generics is to try to rescue the notion the number of members of the category with the property (e.g., the number of robins that do indeed lay eggs). -->

The present paper presents the first formal theory of genericity in language that generates quantitative predictions about human behavioral data. 
A number of other theories of genericity have been proposed in formal semantics and in psychology, which posit different constructs or psychological mechanisms to account for the diversity of generics.
These accounts fall into two broad camps: Those that appeal to quantification or the statistics of the world (e.g., how many Ks have F) and those that appeal to conceptual representations or abstract beliefs (e.g., *there is something about being K which causes it to F*).
Statistical and conceptual theories express the major contrasting views of the truth conditions of generic statements [@Carlson1995essay].^[We use the terms statistical and conceptual to refer to what @Carlson1995essay referred to as "inductive" and "rules and regulations" views, respectively.]

\ndg{[this should go after other theories are introduced.]
In our account, the core meaning of generics concerns probability (the currency of belief), which in many cases may be the byproduct of rich conceptual structure. 
The separation between conceptual structure (which exists in the head) and prevalence (a quantitative metric for natural language semantics) provides a unified view of the phenomena of generics and a single answer to the semantic question: "what do generics mean?"
By formalizing how background knowledge influences generic understanding, our model provides a path towards unifying conceptual approaches to generics with an inherently statistical natural language semantics.
}

<!-- At the same time, utterances are interpreted by listeners whose beliefs about prevalence result from internal models of how the world works.  -->


<!-- By contrast, our theory has made hundreds of predictions about individual generic statements, derived from a general theory that we posit applies to all generic statements. -->
<!-- We now turn to situating our account with respect to these previous theories. -->
<!-- By and large, these theories are concerned with explaining *generics* or generalizations about categories, so in keeping with the spirit of these authors, we will refer to the object of explanation, without loss of generality, as *generics*. -->


### Conceptual accounts

Conceptual accounts try to identify the core meaning of a generalization directly with aspects of conceptual structure.
The most influential account in psychology comes from @Leslie2008. 
Leslie uses the same starting point as our account: Generics express generalization. 
She then turns her attention to the psychological literature on infant generalization to argue that generics tap into an innate, default mechanism that signals the child (or adult) to generalize the property to the kind.^[
  Because the mechanism for understanding generics is innate, in her account, the learning puzzle (vis a vis quantifiers) immediately goes away.
]
Leslie describes the *default generalization* mechanism as having three components: the ability to (i) identify whether or not F is a *characteristic* property of K (e.g., one characteristic property for an animal would pertain to the mode of locomotion for the animal), (ii) identify whether or not F is *striking* (e.g., can kill you; "Mosquitos carry the West Nile Virus"), and (iii) segment *counterinstances* (Ks which do not have F) into positive and negative counterinstances (i.e., Ks which have some alternative positive property *alt F* and Ks which simply lack F, respectively).^[
  This positive vs. negative counterinstance distinction is a rather technical consideration [though not without psychological foundation, see @Leslie2008, p.36] used to account for the difference between examples like "Birds lay eggs" vs. "Birds are female". 
  For the latter, male birds are positive counterinstances because they have an alternative property (being male). 
  For the former, male birds are negative counterinstances because they simply lack the property (i.e., male birds do not reproduce by some other method).
  We will not discuss this consideration any further other than to note that that the difference between "Birds lay eggs" and "Birds are female" can be explained by by a different mechanism (e.g., informativity with respect to a prevalence prior).
  The notion that alternative features may come into play in generic interpretation may also be addressed with feature-wise comparison classes (described above).
]
On this account, generics are true if *some* Ks have F when all counterinstances are negative and the property is either characteristic or striking. 
If the property is neither characteristic or striking, then almost all Ks must have F for the generic to be true (e.g., "Barns are red").
We believe that many of the key factors in this conceptual approach are compatible with our predictive probability approach: what is required is that the distinctions made by conceptual accounts influence predictive probability, which then mediates linguistic effects.

#### Default generalizations

Some might object at this point and argue it is not desirable to define generics in terms of quantifiers, because generics are in many ways *more fundamental* than quantifiers [@Leslie2008; @Gelman2009].
For example, young children learn that meaning of generics far earlier than they know what quantified language means [@Gelman2015].
Similiarly, if you tell adults novel information about categories using quantified language (e.g., "Most spiders shed their skin") and later ask them to recall that information, they will tend to recall the information using generics [e.g., "Spiders shed their skin"; @Leslie2012], but not visa versa.
Rather than the contradictory to the idea that prevalence is at core of 


#### Striking generics

The evolutionary argument for accepting striking generics (e.g., "Tigers eat people") is straightforward: These are relevant properties to know about if you want to survive. 
But there are two other factors that are confounded with striking properties that make it difficult to evaluate a claim about strikingness *per se* (as opposed to beliefs about prevalence) leading to generic endorsement.
The first is that striking properties are rare in the environment: Most animals do not maul children, eat swimmers, or carry malaria.
Thus, the prevalence prior distributions of these features may be hard to distinguish from properties that are just generally rare and distinctive (e.g., *having extraordinarily beautiful feathers*; see also our Expt. 2a, e.g., the distributions for *steals cars* vs. *climbs mountains* for an example with habituals). 
@Cimpian2010 (Expt. 4) found participants willing to endorse generics about both striking properties (e.g., "Lorches have dangerous feathers") and distinctive properties (e.g., "Lorches have distinctive feathers") about equally as often each other and more so than neutral properties (e.g., "Lorches have purple feathers"). 
This similar increase in endorsement for striking and distinctive properties suggests that the prevalence prior $P(p)$ distributions for the two are similar.
@Cimpian2010's experiments did not measure the prevalence prior distribution, but we have found in pilot work that the prevalence prior distribution changes to resemble that of a distinctive property when participants are supplied information about the dangerousness of a property.

The second factor confounded with striking properties is that striking properties may be projected more strongly (i.e., generalized to more instances of the category) than neutral properties.^[
  This observation is also made by @Leslie2008 (p.42), who uses it as motivation for elevating striking properties to their special status in her theory.
]
Interesting, this enhanced projectibility holds for both dangerous properties (e.g., people doing criminal actions) as well as neutral but distinctive properties [e.g., people taller than 6'5"; @Rothbart1978, Expts. 2 & 3].
Thus, there is evidence for the influence of strikingness on *predictive prevalence*, which we posit is an intermediate representation between conceptual knowledge and generic endorsements.
Thus, strikingness may influence endorsement by either (i) altering the prevalence priors or (ii) influencing speaker's predictions about future prevalence; we do not know of any evidence that shows an effect of strikingness while controlling for these mediating factors.
If there are none, then the effects of strikingness would be accounted for by our prevalence-mediated theory.

#### Principled and statistical connections

@Leslie2008's notion of *characteristic* properties is similar to @Prasada2006's notion of a *k-property* (*k* for kind), which is a property that bears a *principled connection* to the kind. 
A property bears a principled connection to the kind if a generic sentence of the following form is endorsed:
"Ks, by virtue of being the kind of things that they are, F" (e.g., "Dogs, by virtue of being the kind of things that they are, are four-legged"); if such a sentence is not endorsed (e.g., "Barns, by virtue of being the kind of things that they are, are red") while the simple bare plural is endorsed (e.g., "Barns are red"), then the property is thought to bear a *statistical connection* to the kind (a so-called *t-property*, for emphasizing that it is the *tokens* having the property which matters for generic endorsement).
@Prasada2013 showed that different kinds of generic statements (e.g., characteristic properties with low prevalence, striking properties, etc., see our Expt. 1) support different kinds of inferences (e.g., *by virtue of*, *normative*: "Dogs are supposed to have four legs", *aspect*: "Having four legs is one aspect of being a dog").
Additionally, there is some evidence that the impact of principled connections on interpretations is separate from their influence on beliefs about prevalence [@Prasada2006]. 

Where do principled connections come from? 
Both @Prasada2006 and @Leslie2008 surmise that a property may qualify as characteristic (or having a principled connection) if there exists an overhypothesis about that property for a relavant superordinate category [e.g., each kind of animal has a means for self locomotion; @Goodman1955; @Shipley1993].
Overhypotheses are naturally formalized as hierarchical Bayesian models, wherein a learner acquires knowledge at multiple levels of abstraction [e.g., learning from the same event about a particular dog, dogs in general, and animals in general; @Kemp2007].
These heirarchical models yield differences in predictive probability that are particularly robust.
Integrating a hierarchical model of kinds and properties with our model of generic language is a natural future direction towards understanding the computational underpinnings of principled connections. 
Different conceptual structures may give rise to roughly the same distributions on prevalence and thus have similar endorsement profiles according to our model. 
Yet the inferences that can be drawn from hearing these generics may differ, depeding on their interactions with the (possibly hierarchical) knowledge people bring to bear [a la the differences observed for "prevalence-matched items" in @Prasada2006]. This is an intruiguing direction for future work.


<!-- , and thus, even though the generic can imply the same prevalence, listeners have overall different inferences (e.g., about the *virtue of* sentence). -->


<!-- The focus of this other empirical work is about highlighting the differences among generics, while our focus is to highlight what is common. -->


<!-- Rich, structural mental representations can be formalized in probabilistic models, which can be used to derive quantitative predictions about inferences derived from that knowledge [@Tenenbaum2011].  -->
<!-- For example, @Kemp2008 introduced a model for learning different kinds of structural relationships between objects and properties (e.g., taxonomies, social cliques, dominance relations). -->
<!-- @Goodmanconcepts argue that concepts and intuitive theories can be constructed from elementary random primitives using insights from *probabilistic programmming*.  -->

<!-- our account is really about what is common among generics, and this is about what is differnet -->
<!-- this is an interesting, albeit crude, result. if true, then this is really about different conceptual structures giving rise to roughly the same distributions on prevalence. even though the generic can imply the same prevalence, you have overall different inferences. our account is really about what is common among generics, and this is about what is differnet. -->






<!-- ### Conceptual accounts -->

<!-- Conceptual accounts of generics emphasize the structure of generic knowledge [@Prasada2000], and view generic utterances as the way of expressing special mental relationships between kinds and properties [@Leslie2008; @Prasada2012]. -->
<!-- These accounts start with the perspective that generics express rich, conceptual relationships between kinds and properties. -->
<!-- That is, "Bishops move diagonally" not because of a statistical relationship, but rather, because those are the rules of the game; if you start moving the bishop other ways besides diagonally, you cease to be playing chess. -->


<!-- If a lion lacked the capacity to roar, we might consider a less good example of being a lion because "lions roar". -->

<!-- The most influential conceptual account of generics is from @Leslie2007. -->
<!-- For Leslie, generics are tied to the cognitive system's "default mode of generalization", which infants seem ready to make use of by drawing strong generalizations from small amounts of data [e.g., @Baldwin1993]. -->
<!-- Leslie's "default mode" comes equipped with the ability to single-out *striking properties* (e.g., properties which are dangerous or appalling) as particularly useful aspects of the world to know about. -->
<!-- Hence, "Mosquitos carry malaria" is true because malaria can kill you and is useful to know about. -->

<!-- This accounts predicts that generics that convey striking properties should be endorsed even when they are relatively rare in the category (i.e., low referent-prevalence; e.g., "Sharks attack swimmers"). -->
<!-- Indeed, naturalistic examples (e.g., "Sharks attack swimmers") and artificial examples (e.g., "Lorches have purple feathers")  supplemented with striking information (e.g.,"These feathers are as sharp as needles and can easily get lodged in you, causing massive bleeding") are endorsed when the prevalence is quite low (e.g., 30\% of lorches have purple feathers; @Cimpian2010; see Expt. 1 for naturalistic cases). -->
<!-- In pilot work, using a paradigm similar to the prior manipulation paradigm employed in the causal language experiments (Expt. 3a), we have observed that the prior distribution over the prevalence $P(h)$ change when supplied information about the dangerousness of the feature. -->
<!-- That is, our pilot work suggests that experiments that experimentally induce beliefs about the dangerousness of a feature also manipulate the prevalence priors.  -->
<!-- Thus, our model would also predict these effects, but by way of the prevalence priors rather than some direct connection between generics and striking features. -->
<!-- However, we do not dispute that extra-linguistic factors can play a role in endorsements of generalizations (e.g., a speaker may not *want* a hearer to believe the generalization, which she herself knows to be true, or visa versa; more on this below). -->

<!-- Of course, not all generics convey striking or appalling information (e.g., "Birds lay eggs"). -->
<!-- Leslie's default mode, thus, also distinguishes *negative counter-instances* of a property (e.g., a bird that doesn't lay eggs, such as a male bird) from *positive counter-instances*  (e.g., a hypothetical bird that bears live young) -->
<!-- The conceptual account argues that generics are much less reasonable when *positive* counter-instances exist.  -->
<!-- For example, "Birds are female" seems weird because *being male* is a *positive* counter-instance of *being female*, but since there are no birds that bear live young (i.e., no *positive counter-instances*),  "Birds lay eggs" is fine. -->
<!-- In the current version of our theory, both kinds of counter-instances influence the referent-category feature-probabilities, though only positive counter-instances could impact the statistical details of the comparison class (in particular, when constructed with respect to the feature; see discussion about the Comparison Class). -->
<!-- Thus, the notion of *positive* and *negative* counter-instances may result from a particular way of looking at the constructs posited in our model, namely prevalences within- and across- categories or features. -->

<!-- Finally, generics are not limited to conveying rich, conceptual information; they are also used to describe facts of the world.  -->
<!-- "Ravens are bigger than toasters" is a true statement, but not because of a rich relationship between ravens and toasters. -->
<!-- "Barns are red" because most barns are red. -->
<!-- If farmers around the world decided to paint their barns green, the things they would be painting would still be barns; in that world, we might say "Barns are green". -->
<!-- Thus, conceptual accounts must be supplemented with the proviso that in ceratin situations, the statistics of the world are relevant.  -->

<!-- Our view is that subjective probabilities can be formed either from worldly observations or because of the structure of people's mental representations. -->
<!-- In the last fifteen years, there has been tremendous progress in formalizing  -->
<!-- Rich, structural mental representations can be formalized in probabilistic models, which can be used to derive quantitative predictions about inferences derived from that knowledge [@Tenenbaum2011].  -->
<!-- For example, @Kemp2008 introduced a model for learning different kinds of structural relationships between objects and properties (e.g., taxonomies, social cliques, dominance relations). -->
<!-- @Goodmanconcepts argue that concepts and intuitive theories can be constructed from elementary random primitives using insights from *probabilistic programmming*.  -->

<!-- In this paper, we take a minimalist approach to modeling conceptual structure, incorporating only what is necessary into the interpreter's background knowledge, the prior on prevalence $P(h)$. -->
<!-- In our Bayesian data analysis of background knowledge, we use a mixture model that reflects basic knowledge about kinds and properties (e.g., that most kinds don't have most properites).   -->
<!-- It's plausible that more richly structured knowledge of the kind described by @Prasada2013 and @Leslie2007 can be incorporating into the general probabilsitic framework that we use here. -->



<!-- In Expt. 1a, we discovered that a mixture model is necessary to account for intuitions about the prevalence across different categories. -->
<!-- This minimally structured model  -->



<!-- @Prasada2006 and later @Prasada2013 distinguish between \emph{principled}, \emph{statistical}, and \emph{causal} relations within concepts. -->
<!-- Striking generics (e.g. \emph{Mosquitos carry malaria}) show characteristics of \emph{causal connections} (operationalized using the phrase \emph{There is something about Ks that cause them to F}). -->
<!-- Generics like \emph{Birds lay eggs} (in which only a minority have the property) exhibit *principled* connections (operationalized by endorsement of the phrase \emph{In general, Ks have F}). -->
<!-- The fact that generics about different properties license different kinds of inferences is taken as evidence that the generics themselves represent different kinds of relations. -->
<!-- Statistical information takes a backseat to the conceptual structure. -->


<!-- It is also the first attempt in psychology to try to unify significant swaths of language that are seemingly quite different from one another: generalizations about events, causes, and categories. -->

<!-- -- Leslie (2008): Default inferences, could be similar to the cognitive model described, but we don't make strong metaphysical commitments (e.g., to "negative" properties) -->

<!-- -- "default generalization" -- very close, the listener is doing a generalization, but not generalization based on evidence, but by reasoning about the threshold -->

<!-- Generic language is the simple and ubiquitous way by which generalizations are conveyed between people. -->
<!-- Yet the dramatic flexibility of generic language has confounded psychologists, linguists and philosophers who have tried to articulate what exactly generic statements mean.  -->
<!-- We evaluated a theory of generic language derived from general principles of language understanding using a simple, but uncertain, basic meaning---a threshold on property prevalence. -->
<!-- Our formal model is a minimal extension of the RSA theory of language understanding, together with an underspecified threshold semantics. -->
<!-- The model was able to explain two major puzzles of generics: their extreme flexibility in truth conditions and the contrastingly strong interpretation of many novel generics. -->
<!-- Both of these phenomena were revealed to depend in systematic ways on prior knowledge about properties. -->
<!-- This prior knowledge was revealed through Bayesian model analysis to be structured, providing a promising bridge to conceptual accounts of generic language. -->
<!-- To understand the nature of the underlying prevalence scale, we showed that generic language is about speakers' expectations of future prevalence, and not necessarily what the current state of the world is like.  -->
<!-- Across all experiments, the formal model predicted the quantitative details of participants' judgments with high accuracy. -->

<!-- There have been numerous demonstrations arguing that statistics (e.g., property prevalence) are insufficient to explain generic meaning [@Gelman2002; @Gelman2007; @Cimpian2010; @Cimpian2010c; @Khemlani2012; @Prasada2013]. -->
<!-- In these experiments, the prevalence considered is only the prevalence of the property for the referent-category [e.g., the percentage of birds that lay eggs; @Khemlani2012; @Prasada2013], what we have referred to as \emph{within-kind prevalence}.  -->
<!-- Indeed, this simple statistic also fails to explain our data (Figure \ref{fig:commongenerics}b, right). -->
<!-- Our formal model of pragmatics, by contrast, considers not only within-kind prevalence, but a listener's prior beliefs about prevalence across kinds in order to arrive at a meaning for a generic utterance. -->
<!-- By establishing the validity of a semantics based on prevalence alone, we provide a formalism to learn about categories from generic statements.  -->
<!-- Further, since prevalence is a probability, our model can take information conveyed with a generic and be naturally extended to make predictions about entities in the world or support explanations of events or behavior. -->


### Statistical accounts

#### Relative and absolute generics

Our underspecified threshold model has clear antecedents in other statistical accounts, most notably @Cohen1999's theory of generics as a frequency adverb (e.g., "generally").
Cohen treats generics as comprising two qualitatively different types: *relative* and *absolute* generics.
<!-- For Cohen, the statement "Birds lay eggs" means "Generally, birds lay eggs", and then he takes up the task of explaining what "generally" means. -->
*Absolute generics* use a fixed, 50\% threshold on prevalence: $P(F\mid K)>0.5$. 
That is, if a particular instance is more likely than not to have the feature, then the absolute generic is true.
By contrast, *relative generics* are true based on a comparison to an alternative set of kinds (his notation: $Alt(K)$), analogous to our comparison class.
"Mosquitos carry malaria" is true because an arbitrary mosquito is more likely than an arbitrary member of an alternative kind to have the feature.

In our model, we treat all generics as relative. 
Attested differences in endorsement and interpretation, then, emerge through the interplay of prior knowledge with our uncertain semantics.^[
  For a related theoretical argument against the "relative" / "absolute" distinction for gradable adjectives, see @Lassiter2015.
]
Further, though Cohen's theory is framed in terms of probabilities, it is a fully semantic, fixed-threshold account which only makes deterministic predictions about what is true and what is false.
In contrast, we posit an uncertain threshold which is resolved in context through Bayesian inference; our theory is a joint semantic--pragmatic theory. 

<!-- In our theory, there is uncertainty about the core semantic meaning, and this uncertainty (though reduced in context) drives the model to make graded predictions about endorsement. -->
<!-- Second, Cohen draws an *a priori* distinction between *Absolute* and *Relative* generics, and provides different mechanisms for each each. -->
<!-- We used examples of both in our stimuli (Expt. 1) and found that our single model handles both without any addition assumptions, casting doubt on the *a priori* distinction between "absolute" and "relative". -->

Cohen's and other statistical theories rely upon an additional mechanism (not currently required in our account) to explain the context-sensitivity of generics: contextually restricting the entities that go into the computation of prevalence (i.e., which robins do we look at to compute the probability of laying eggs among robins?).
This mechanism is called *domain restriction*. 
@Cohen1999 posits that prevalence is calculated by only considering entities that *could have some feature* in a contextually-specified alternative set of features (so called $Alt(F)$).
For example, the property "lays eggs" induces a set of alternatives that are associated with modes of reproduction (e.g., "gives birth to live young", "undergoes mitosis", ...).
"Robins lay eggs" is evaluated as an *absolute generic* as only individuals that are female members of kinds are under consideration, because only the female members can plausibly satisfy one of the other alternatives having to do with reproduction (i.e., the alternative features in $Alt(F)$).
The inferential machinery of domain restriction (i.e., what comprises $Alt(F)$) relies upon conceptual information, but the details remain obscure [@Carlson1995essay].^[
  However, see @Cohen2004 for a discussion of how his semantic constraints relate to different kinds of generics and different kinds of conceptual representational frameworks used in cognitive science.
]
The mechanism of domain restriction may be implicit in our own theory: the prior distribution over the prevalence of *lays eggs* presumably includes aspects of people's theories about reproduction (i.e., that only females lay eggs).
Thus, there may exist a refactorization of the uncertain threshold model to a fixed threshold where the listener has uncertainty about the relevant domain restriction.

<!-- Of course, the inferential machinery behind this sort of domain restriction (i.e., what is $Alt(F)$?) requires further theorizing to explain.  -->

#### Generic as indexical

@Sterken2015 takes a novel starting point for her analysis: Generics are inherently context-sensitive.
To understand the properties of generics, she looks to another inherently context-sensitive part of language: *indexicals* (e.g., "this" or "I").
@Sterken2015 posits a context-sensitive "quantificational force" as well as domain-restriction [of the kind used by @Cohen1999 and others].
Our uncertain-threshold semantics can be seen be a particular formalization of @Sterken2015's context-sensitive *quantificational force*. 
We have not had need for employing domain restriction on the categories, though as noted above, it is a potential avenue for future development.
<!-- Finally, how the context-sensitivity of an indexical differs from the kind of context-sensitivity with an uncertain-threshold is an important question for future research. -->

#### "Normal" accounts

A popular alternative view under the statistical banner draws on the intuition that generics express something normative in the world [@Asher1995; @Pelletier1997; @Nickel2008]. 
For example, "Dogs have four legs" is a good generalization even though, regrettably, not all dogs have four legs. 
However, were the world to function *normally* (e.g., dogs would not be involved in freak-tractor accidents or be born with strange genetic mutations), then *all* dogs would have four legs. 
The idea that our beliefs about what is normal in the world influences our judgments about generalizations has intuitive appeal for rejecting accidentally true generalizations (e.g., "Supreme Court justices have even social security numbers"; described in more detail below) and stereotyped language (e.g., "Boys are good at math”).
Our theory does not directly formalize "what is normal", though we argue that a speaker's beliefs about what is *probable* [which may relate to what is *normal*; see @Icard2017] plays a role in endorsing and interpreting generalizations. 
<!-- We showed in Expt. 2c that a speaker's beliefs about what is likely to be the case in the near future matters above and beyond what is currently true in the world for endorsing generalizations.  -->
<!-- Our notion of prevalence is as a predictive probability, which incorporates background knowledge in order to make predictions about the future.  -->

#### Underquantification

A proposal similar to our account concerning underspecification of generics has been made in the computational linguistics literature [so-called *underquantification*; @Herbelot2011].
In their model, generics express an explicit quantified relation, specifically either "Some", "Most", or "All".
The task of the computational linguist, then, is to construct a set of features that accurately predicts (relative to human judgments) the quantified relationship expressed by the generic [analogous to a quantifier version of the *implied prevalence* task used in @Gelman2003b; @Cimpian2010]. 
Our semantic theory can be seen as a generalization of *underquantification* to a continuous interval of possible meanings.
This distinction is relevant for the acquisition of the language of generalizations; we do not take as primary the quantified relations (e.g., "Some", "All").
<!-- Formally, whereas the *underquantification* account posits that a generic is *ambiguous* between various meanings, we argue that the generic is *vague*, and has a continuum of possible meanings.  -->
Additionally, by using an underspecified threshold, our formulation naturally extends to other scales and other kinds of generalizations (e.g., habitual language), where quantified relations like "Most" or "All" are not directly applicable. 

## Other philosophical puzzles

In this paper, we aimed to balance two competing goals in designing our experimental stimuli: (1) including some familiar, philosophically puzzling examples that have been discussed in the vast literature on generic language and (2) introducing novel stimuli that provide targeted quantitative tests of our model vis-a-vis alternative models.
We close by discussing how a three previously-discussed examples could be addressed in our communicative framework.

**1. Mary handles the mail from Antarctica (*yet has never had the opportunity*).**

Imagine there is a job in the local bureaucrat's office to handle the mail from Antarctica and this job is assigned to Mary; to date, however, there has never been any mail from Antarctica [@Cohen1999]. 
That is, the statement "Mary *has handled* mail from Antarctica" is false.
Sentence (1) is still thought to be intuitively true despite zero actual instances of the event.
In our framework, Sentence (1) is a extreme case of generalizations expressing *predictive* probabilities.
In Expt. 2c., we experimentally dissociated predictive probability from past frequency, finding that generalization endorsement tracked predictive probability, but not frequency.
We expect the same to be true with Mary: any future mail coming from Antarctica will be handled by Mary. 
Thus the predictive probability that Mary will handle Antactican mail, if there is any, is high.
Predictive probabilities often track past frequency or actual prevalence in the world, but people's internal models of how the world works can lead them to diverge. In this case our understanding of Mary's job leads to a strong preditcive probability in the absence of past frequency evidence.

**2. Supreme Court Justices have even social security numbers.**

Imagine that every current and past Supreme Court Justice has a social security number which is an *even number*. 
Sentence (2) is still considered false, even though the property holds for exactly 100\% of the category [@Cohen1999].
We predict the rejection of Sentence (2) is the result of abstract, intuitive theories guiding our subjective predictive probabilities.
That is, because observers strongly believe one's social security number does not influence selection for the Supreme Court, speakers would assign a roughly 50\% subjective probability that the *next* justice would have an even social security number.
Then, if we constructed the comparison class by considering other professionals, Sentence (2) would be rated similarly by our model as "Birds are female", because all professions have roughly the same probability of having employees with even social security numbers.

However, were we to learn much more surprising information---for instance, if every Supreme Court Justice in U.S. history had a social security number which was a *prime number* (a much lower probability outcome)---the shear suspiciousness could compel an observer to revise their theory of the domain (appealing perhaps to a conspiracy), update their subjective probability of future instances, and then accept the generic. 
That is, our theory predicts there are situations where statements like (2) could be considered felicitous generalizations.

**3. Elephants live in Africa and Asia.**

Understanding how a semantic representation *composes* is another important test for a theory of generalizations in language.
@Nickel2008 suggests Sentence (3) is semantically equivalent to: "Elephants live in Africa and elephants live in Asia".
Statistical accounts of generics have trouble with this kind of conjunction: It cannot be the case that *most* (more than half) elephants live in Africa and *most* (more than half) elephants live in Asia, unless we are to posit *international elephants* (i.e., individual elephants who live part-time in Africa and part-time in Asia), which we would rather prefer not to posit.
However, this is the only interpretation available if the generalization is given a fixed, majority based quantificational semantics, as posited in most statistical views of generics (e.g., if the generic means *most*).
Our theory does not provide a fixed semantics for generalizations, but an uncertain one, which can be updated as more information comes in.
In fact, with prior knowledge suggesting against the existence of international elephants and without any further semantic assumptions, our model interprets Sentence (3) as meaning some elephants live in Africa and that different ones live in Asia.^[
  An implementation of this example can be found: [http://forestdb.org/models/generics-conjunction.html](http://forestdb.org/models/generics-conjunction.html).
]
Interestingly, an incremental parsing of Sentence (3) (i.e., upon hearing only the first part of the sentence that "Elephants live in Africa") leads our model to believe that *most* elephants live in Africa.
When the sentence is completed ("...and Asia"), the model non-monotonically updates its beliefs to something weaker: *some* elephants live in Africa (and others in Asia, but few in other places).
The flexibly of our model accommodates new evidence that might otherwise contradict previous utterances because it maintains uncertainty about the precise meaning of the utterance.

<!-- Instead, the statement should be glossed as *some elephants live in Africa* and *some elephants live in Asia*, and perhaps taken collectively, *most elephants live in either Africa or Asia* [@Nickel2008].  -->
<!-- This reading of (3) gives it the same semantic content as two statements: "Elephants live in Africa. Elephants live in Asia." -->
<!-- Our model is able to flexibly accomodate this statement by having uncertainty about the truth-conditional threshold.  -->

<!-- With reasonable assumptions about the prior (e.g., that *lives in* is similar to other biological properties from Expt. 1a and assuming international elephants are unlikely *a priori*), upon the hearing "Elephants live in Africa", our model will infer that most elephants live in Africa. -->
<!-- When the model then hears "Elephants live in Asia", the model updates its beliefs to accomodate this second statement,  -->
<!-- This is possible because our model has uncertainty over the semantic thresholds in the generic claim. -->

<!--
**4. Books are paperbacks.**

Sentence (4), strikes hearers as *odd* or perhaps *false*, despite the vast majority of books being paperback. 
Why?
We first observe that the sentence is constructed by pairing a category ("Books") with a property that describes a strict subset (i.e., "paperbacks"). 
We hypothesis that the starngeness of (4) has to do with the role of *predicability* [in the sense of @Keil1979, originally from @Sommers1963] in determining the comparison class.
That is, assume that entities in the relevant comparison classes must be predicable of the property: each entity in each class must either have or not have the proprerty.^[
  Note that this assumption is consistent with the comparison classes we have assumed in our three case studies.
]
Then, "is paperback" can only be informatively said of individual books, because these are the only objects that can plausibly have the property; that is, world knowledge gives us that an elephant cannot be predicated (either true or falsely) by the property "is a paperback".^[
  Note that this idea is related to @Cohen1999's notion of "Relative generics" (described above), which have truth conditions that are determined by a comparison to an alternative set of Ks which is composed of Ks that could satisfy some F in an alternative set of Fs.
]
The relevant aggregations of entities (i.e., of individual books), then, are collections of books (e.g., books of different genres or publication eras among other such sub-categories).
Then, given that "books" is the superordinate category of "kinds of books", the referent-category prevalence (the % of books that are paperbacks) is the mean of the prevalence prior (the average of the % of sub-classes of books that are paperbacks).
Given this prevalence prior and the referent-prevalence, our endorsement model would predict "Books are paperbacks" is neither true nor untrue, in a way analogous to "Robins are female". 
We expect these intuitions to generalize to other examples expressing an analogous relation (e.g., "Pastas are spaghetti", "Animals are humans").

 
```{r booksArePaperbacks, fig.cap="Sketch of an argument for why 'Books are paperbacks' sounds odd. The feature 'is paperback' can only be predicated (in the sense of @Keil1979) of individual books, which are organized into collections (here, by genre). The prevalence prior is constructed by aggregating these collections of books. Then the prevalence of 'is paperbook' for the category of 'books' can never be higher than the mean of the prior distribution. The endorsement model would give this sentence a rating of 0.5, corresponding to neither true nor false."}
knitr::include_graphics("figs/books-paperbacks.pdf", dpi = 108)
```



**4. Women are submissive.**

Finally, Sentence (4) suggests that a property can be widespread relative to other kinds or groups, as well as being so systemic that we would predict it to be the case in the future (high *predictive prevalence*), and speakers still might find it aversive to actually endorse the generalization [@Haslanger2011]. 
( Due of a variety of socio-cultural reasons, @Haslanger2011 argues that women tend to be submissive (more so than men, and many other social categories), yet still cautions against asserting (5). )
In our **Model Simulations** section, we showed that the generalization often implies the property is widespread, even with relatively uninformed prior beliefs about the property. 
If the generalization conveys the property is in fact more widespread than the speaker herself might believe, this can lead to a distortion of the truth [@Cimpian2010].
The current formulation of our model is relatively ambivalent about the deviations of the listener's beliefs from the speaker's belief (i.e., the speaker doesn't mind that the prevalence that she believes to be true will be exaggerated in the mind of the listener).
However, if states of the world (or, listener's beliefs about states of the world) have different *subjective values*, speakers who take into the account the subjective utilities of the listener may produce language that deviates from what a pure informational transmission speaker might say.
This kind of extension to rational models of communication has already been used to account for a variety of phenomena in *polite language* use [@Yoon2016; @Yoon2017].
Such a value-based utility structure for states of the world for language about social categories may capture intuitions like those about Sentence (4): If the speaker found states of the world where the probability of the feature is high as undesirable (e.g., a world where many women were submissive), then a speaker who considered both the informational content of the utterance and the utility in the states of the world implied by that utterance would too find it reprehensible to make such a generalization.

An alternative information-theoretic analysis of (4) could be made concerning the conceptual structure communicated by generalizations (see earlier discussion of *Prevalence Priors and Conceptual Structure*). 
Suppose there are two possible causes for a person to be submissive: Either it is in their DNA or the person was socialized in such a way as to be submissive. 
Were either of these possible causes to exist for a particular group (e.g., women), then high prevalence of the property would be expected in that group. 
A speaker may intend to communicate not the high prevalence, however, but what she believes is the generative cause of that high prevalence (i.e., either that there is an internal, DNA cause or an external, societal cause).
Suppose the speaker wants to communicate that she believes an external, societal cause is leading to high prevalence of submissiveness.
The decision to endorse (4) depends upon what the speaker believes her listener will infer. 
If she is in a group of close friends discussing the ways in which society shapes behavior, the speaker may opt to endorse (4) because with high probability, she will be understood as endorsing the external, society cause. 
However, if she is worried that some might take her to mean that there's something about women that causes them to be submissive, the speaker may refrain from uttering (4).
Such an explanation would be a purely information transmitting account that does not require any social utility to explain the behavior.

-->


<!--
In sum, we've tried to argue that our information-theoretic communicative model couched in our general cognitive framework might well explain a number of interesting and heretofore puzzling phenomena in genericity as well as make novel predictions about a wider range of language.
-->

<!-- -- Books are paperbacks. (failure of the constrast class) -->
<!-- -- Birds lay eggs and are female vs. Elephants live in Asia and Africa -->
<!-- can use pragmatics to resolve if the property is conjunctive or not.  -->
<!-- -- Women are submissive. (Haslanger, 2011; generics + politeness mechanism, some states have lower value than others) -->
<!-- -- Muslims are terrorists (vs. Mosquitos carry malaria) -->
<!-- -- Mary handles the mail from antarctica (predictive propensity; also highlights domain restriction on events) -->
<!-- - Glass breaks when struck. (so-called "disposition", but here: a generalization about the event of a glass being struck [already we are domain restricted]) -->

# Conclusion

It might seem paradoxical that a part of language that is so common in communication and central to learning should be vague. 
Shouldn't speakers and teachers want to express their ideas as crisply as possible?
To the contrary, underspecification can be efficient, given that context can be relied upon to resolve uncertainty in the moment [@Piantadosi2012].
In our work, context takes the form of shared beliefs between speakers and listeners. 
By leveraging this common ground, the language of generalizations provides a powerful way to communicate and learn generalizations, which would otherwise be difficult or costly information to learn through direct experience.

<!-- The dark side of this flexibility is the potential for miscommunication or deceit: A speaker might assert a generalization that she herself would not accept, conveying a too-strong impression to a naive listener. -->
<!-- Our model predicts this potential particularly for properties which, when present, are widespread in a category; biological properties are believed to have this distribution, but many properties of social categories may as well [@Cimpian2011a; @Cimpian2012b; @Rhodes2012]. -->
<!-- Disagreements are also predicted when interlocutors fail to share background assumptions, which could manifest as differences in the prior distributions on prevalence or what goes into the comparison class. -->
<!-- Core aspects of political disagreement then (e.g., as to whether "Humans cause global warming") could be derived from differences in the estimated causal responsibility of the category in question (e.g., what impacts humans are having), of *other forces* (e.g., plate tectonics), as well as the comparison class of other forces (e.g., what are the alternative causes?).  -->
<!-- This is an important area for future research. -->

Categories are inherently unobservable. 
You cannot see the category \textsc{dog}, only some number of instances of it.
Yet we easily talk about these abstractions, conveying hard-won generalizations to each other and down through generations.
<!-- The theory presented here gives one explanation of how we do so, providing a computational perspective on how we communicate generalizations and how beliefs play a central role in the meaning of words. -->
The theory presented here provides the first computational perspective on how we communicate generalizations, illustrating how beliefs play a central role in the meaning of words.

\newpage

# References 

<!-- \setlength{\parindent}{-0.1in}  -->
<!-- \setlength{\leftskip}{0.125in} -->
<!-- \noindent -->

<div id = 'refs'></div>

\newpage

```{r child = 'appendix-cvDerivation.Rmd'}
```


\newpage
```{r child = 'appendix-cueValidity.Rmd'}
```


\newpage

```{r child = 'appendix-bda.Rmd'}
```

\newpage

```{r child = 'appendix-habitualsItems.Rmd'}
```