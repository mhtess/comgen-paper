```{r echo = F}
library(langcog)
library(tidyverse)
library(ggthemes)
library(jsonlite)
theme_set(theme_few())
project.path <- "../"
data.path <- "data/generics/endorsement/"
substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}
```

# Appendix: Bayesian Data Analysis

## Case Study 1: Generic language

### Modeling feature-probability priors

In Case Study 1 (Generic Language), we elicited the prevalence of features for many different categories. 
These can be thought of as *samples* from the feature-probability prior distribution. 
Formally, we assume the prior data (analyzed independently for each property) was generated from one of two distributions: a distribution corresponding to those kinds with a stable causal mechanism that *could* give rise to the property ($\mathcal{D}_{stable}$) and a "transient cause" distribution corresponding to those kinds without a stable mechanism ($\mathcal{D}_{transient}$).
The "transient" distribution intuitively corresponds to accidental causes of the feature (e.g., a lion, who through some genetic mutation, reproduces by laying eggs).
We model this distribution as a Beta distribuition that heavily favors probabilities near 0: $\text{Beta}(\gamma = 0.01, \delta = 100)$.^[
  Note that we use the noncanonical mean $\gamma$ and concentration $\xi$ (or, inverse-variance) parameterization of the Beta distribution rather than the canonical shape (or pseudocount) parameterization for ease of posterior inference. The shape parameterization can be recovered using: $\alpha = \gamma \cdot \xi; \beta = (1 - \gamma) \cdot \xi$.
]
The "stable" distribution is modeled as a Beta distribution with unknown parameters $\text{Beta}(\gamma, \xi)$.^[
Because the Beta distribution is not defined at the points 0 and 1, we add $\epsilon$ to the 0 responses and round 1 to 0.99.
Adjusting 1 to $1- \epsilon$ leads to improper inferences for this model, as $1 - \epsilon$ is only likely under a highly right-skewed distribution; treating 1 as $1- \epsilon$ disproportionately influences the shape of $\mathcal{D}_{stable}$ relative to other responses.
This problem does not appear for 0 being adjusted to $\epsilon$ because the "transient" distribution already expects such low values.
Similar results can be obtained by rounding 0 to 0.01. 
Alternatively, the "transient" distribution could be defined as a Delta distribution at 0, and 0 responses could remain in their raw form.
]
Finally, we assume that these two components combine with mixture weighting $\phi$ such that the data we observe is $$P(d) = \phi\cdot \text{Beta} (d \mid \gamma, \xi) + (1 -  \phi) \cdot \text{Beta}(d \mid \gamma = 0.01, \xi = 100) $$.
<!-- The unstructured alternative hypothesis assumes the data was generated by a single component in the prior distribution with unknown parameteres $P(d) = \text{Beta} (d \mid \gamma, \xi)$. -->
We put the following priors over the latent parameters of the model:
\begin{eqnarray}
\phi_i & \sim & \text{Uniform}(0, 1) \\
\gamma_i & \sim & \text{Uniform}(0, 1) \\
\xi_i & \sim & \text{Uniform}(0, 100)
\end{eqnarray}
where $i$ ranges over the different properties (e.g., *lays eggs*, *carries malaria*).

To learn about the credible values of the parameters, we ran separate MCMC chains for each item, collecting 75,000 samples, removing the first 25,000 for burn-in.
To see how well the mixture model fits the feature-probability prior data, we use the inferred parameters to generate new data.
The data generated from the model's posterior is called the *posterior predictive distribution* and is an important step in model criticism. 
If the model is a good representation of the data, the posterior predictive data will align with the observed experimental data. 
We construct a posterior predictive distribution by "forward sampling" the model.^[
This can be described by the following algorithm: First, flip a coin weighted by $\phi$.
If it comes up heads, we then sample from the "stable" component: $\text{Beta}(\gamma, \xi)$.
If it comes up tails, we sample from the "transient" component: $\text{Beta}(0.01, 100)$.
We do this many times using the posterior distibution to generate a distribution over predicted feature-probability ratings.
]

## Jointly modeling referent feature-probability, feature-probability priors, and generic endorsements

To fit the generic endorsement models, we incorporate them into the Bayesian data analytic model of the feature-probability prior data (Expt. 1b) to create a single, joint-inference model where the optimality parameter $\lambda_1$ is inferred jointly with all the other latent parameters of the full model (the referent feature-probability $h'_{k, f}$ for each category $k$ and property $f$ and the parameters of the feature-probability priors $P_f(h)$ for each property $f$) using data from Expt. 1a \& b (Figure \ref{fig:genericsModelDiagram}).
For the parameters of the feature-probability prior distributions, we use the same priors described in Expt. 1b; for the speaker optimality parameter, we use a prior with a range consistent with previous literature using the same model class: $\lambda_1 \sim \text{Uniform}(0,5)$.
We learn about the \emph{a posteriori} credible values of the joint inference models by collecting samples from 3 MCMC chains of 100,000 iterations removing the first 50,000 iterations for burn-in, using an incrementalized version of the Metropolis-Hastings algorithm [@Ritchie2016]. 

```{r genericsModelDiagram, fig.cap="Graphical model corresponding to the fully Bayesian data analysis of the RSA model. The feature-probability prior data $d^{pr}_{f}$ is assumed to be generated from the mixture model validated in Expt. 1a. The referent-category feature-probability $d^{pr}_{k,f}$ is generated from a latent feature-probability $h_{k,f}$. The fixed-threshold (control model) or uncertain-threshold RSA model takes the feature-probability prior $P_f(h)$, the referent-category feature-probability $h$, and a single speaker optimality parameter $\\lambda$ as input. This overall structured is repeated (except $\\lambda$) for each of the unique properties $f$ and categories $k$ that correspond to the generic sentences in our stimulus set. Note that RSA corresponds to a probabilistic *function* and not a *random variable* that is standard in graphical model notation; RSA cannot be represented by a graphical model because it has recursion. "}
knitr::include_graphics("figs/generics_bayesnetmodel.pdf", dpi = 108)
```

